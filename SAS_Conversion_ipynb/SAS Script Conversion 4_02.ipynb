{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\"\"\"\n",
    "/* ***************************** */\n",
    "/* Premium Tables for Policy Sea */\n",
    "/* ***************************** */\n",
    "\"\"\"\n",
    "\n",
    "#adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "#ztrnpf_path = '/group/axa_malaysia/data/adm_ztrnpf'\n",
    "#prempf_path = '/group/axa_malaysia/data/adm_prempf'\n",
    "#rprmpf_co_path = '/group/axa_malaysia/data/adm_rprmpf_co'\n",
    "#rprmpf_rp_path = '/group/axa_malaysia/data/adm_rprmpf_rp'\n",
    "#monthend = 0\n",
    "\n",
    "\n",
    "\n",
    "def PREMIUM_PSEA(adm_mapping_path, ztrnpf_path, prempf_path, rprmpf_co_path, rprmpf_rp_path, monthend=0, output_folder='data/sas_402/'):\n",
    "    \n",
    "    def format_date(strdate):\n",
    "        try: \n",
    "            return datetime.strptime(str(strdate),'%Y%m%d').strftime('%Y-%m-%d')\n",
    "        except: \n",
    "            return '2999-12-31'\n",
    "    _format_date = udf(format_date,StringType())\n",
    "    \n",
    "    \"\"\"\n",
    "        /* 1) sacscode filter */\n",
    "        /* Consider Gross Prem (FG) and Co-insurance Prem      */\n",
    "        /* we will consider RP (Re-insurance premium) in  \t   */\n",
    "        /* the next section, since it only needs to run   \t   */\n",
    "        /* once a month - it is a massive table\t\t\t       */\n",
    "        /* 2) batctrcde filter */\n",
    "        /* Only consider real financial transactions      \t   */\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        /* Map Transaction Types */\n",
    "        /* Note - the mapping is limited to the filter, so the mapping is only needed for the\n",
    "           transaction types applied in the filter */\n",
    "        Transaction Types are read from the excel mapping files\n",
    "    \"\"\"\n",
    "    transtype_map = pd.read_excel(adm_mapping_path, sheetname='300').set_index('batctrcde').to_dict()['trantype']\n",
    "    transtype_map_bc = sc.broadcast(transtype_map)\n",
    "\n",
    "    ztrnpf = spark.read.parquet(ztrnpf_path)[['batcactyr',\n",
    "     'batcactmn',\n",
    "     'rldgacct',\n",
    "     'tranno',\n",
    "     'ccdate',\n",
    "     'effdate',\n",
    "     'accnum',\n",
    "     'expiry_date',\n",
    "     'batctrcde',\n",
    "     'sacscode',\n",
    "     'trandate',\n",
    "     'chdrstcdc',\n",
    "     'tranamt01',\n",
    "     'tranamt02',\n",
    "     'tranamt03',\n",
    "     'tranamt04',\n",
    "     'tranamt05',\n",
    "     'batcbrn']].filter( col(\"batctrcde\").isin([\"T405\", \"T409\", \"T413\", \"TA39\", \"T495\", \"T454\"]) )#.limit(100000)\n",
    "    ztrnpf_fgco = ztrnpf.filter(col(\"sacscode\").isin(\"FG\",\"CO\"))\n",
    "    ztrnpf_rp = ztrnpf.filter(col(\"sacscode\")=='RP')\n",
    "\n",
    "    def transformations(df):\n",
    "        df = df.withColumn('yrm', col('batcactyr')*100+col('batcactmn'))\n",
    "\n",
    "        #dates formatting\n",
    "        df = df.withColumn('d_tran', to_date(_format_date(col('trandate'))))\\\n",
    "        .withColumn('d_eff', to_date(_format_date(col('effdate'))))\\\n",
    "        .withColumn('d_com', to_date(_format_date(col('ccdate'))))\\\n",
    "        .withColumn('d_exp', to_date(_format_date(col('expiry_date'))))\n",
    "\n",
    "        df = df.drop('batcactyr','batcactmn','effdate','ccdate','expiry_date','trandate','tranamt01','tranamt02','tranamt03','tranamt04','tranamt05')\n",
    "\n",
    "        #map transaction types\n",
    "        df = df.withColumn('trantype', udf(lambda x: transtype_map_bc.value[x])(col('batctrcde')))\n",
    "        return df\n",
    "\n",
    "    df1 = ztrnpf_fgco.withColumnRenamed('rldgacct', 'chdrnum')\\\n",
    "                .withColumnRenamed('accnum', 'agentid')\n",
    "\n",
    "    df2 = df1.withColumn('gwptotal', when(col('sacscode')=='FG', col('tranamt01') - col('tranamt03') ).otherwise(lit(0)) )\\\n",
    "    .withColumn('gwctotal', when(col('sacscode')=='FG', col('tranamt04') + col('tranamt05') ).otherwise(lit(0)) )\\\n",
    "    .withColumn('cwptotal', when(col('sacscode')!='FG', col('tranamt01') - col('tranamt03') ).otherwise(lit(0)) )\\\n",
    "    .withColumn('cwctotal', when(col('sacscode')!='FG', col('tranamt04') + col('tranamt05') ).otherwise(lit(0)) )\n",
    "\n",
    "    df3 = transformations(df2)\n",
    "\n",
    "    #FIRST GET BASE\n",
    "    base_df = df3.filter(col('sacscode')=='FG').drop('gwptotal','gwctotal','cwptotal','cwctotal','sacscode').\\\n",
    "    sort('chdrnum', 'tranno').dropDuplicates(subset=['chdrnum', 'tranno'])\n",
    "    base_df.cache()\n",
    "\n",
    "    \"\"\"THEN AGGREGATE ZTRNPF\n",
    "        /* ****************************************************************** */\n",
    "        /* Sums gwptotal gwctotal cwptotal cwctotal by chdrnum and tranno     */\n",
    "        /* Since we took only FG transactions the filter is already leaving only one unique chdrnum and tranno combination, \n",
    "        this aggregation mainly used to ensure that there are only one combination.         */\n",
    "        /* ****************************************************************** */\n",
    "    \"\"\"\n",
    "    df4 = df3.groupBy('chdrnum','tranno').sum('gwptotal','gwctotal','cwptotal','cwctotal')\\\n",
    "    .withColumnRenamed('sum(gwptotal)','gwptotal')\\\n",
    "    .withColumnRenamed('sum(gwctotal)','gwctotal')\\\n",
    "    .withColumnRenamed('sum(cwptotal)','cwptotal')\\\n",
    "    .withColumnRenamed('sum(cwctotal)','cwctotal')\n",
    "\n",
    "    #GET DETAIL OF GROSS TRANSACTIONS IN PREMPF\n",
    "    prempf = spark.read.parquet(prempf_path)[[\"chdrno\",\"rskno\",\"tranno\",\"premcl\",\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\"]]\n",
    "    prempf = prempf.withColumnRenamed('chdrno', 'chdrnum')\\\n",
    "    .withColumn('gwp',col('extr01')-col('extr03'))\\\n",
    "    .withColumn('gwc',col('extr04')+col('extr05'))\\\n",
    "    .drop(\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\")\n",
    "    prempf = prempf.groupBy('chdrnum','tranno','rskno','premcl').sum('gwp','gwc')\\\n",
    "    .withColumnRenamed('sum(gwp)','gwp')\\\n",
    "    .withColumnRenamed('sum(gwc)','gwc')\n",
    "\n",
    "    #GET DETAIL OF CO-INSURANCE TRANSACTIONS IN RPRMPF_CO\n",
    "    rprmpf = spark.read.parquet(rprmpf_co_path)\\\n",
    "    [[\"chdrno\",\"rskno\",\"tranno\",\"premcl\",\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\"]].filter(col('sacscode') == \"CO\")\n",
    "    rprmpf = rprmpf.withColumnRenamed('chdrno', 'chdrnum')\\\n",
    "    .withColumn('cwp',col('extr01')-col('extr03'))\\\n",
    "    .withColumn('cwc',col('extr04')+col('extr05'))\\\n",
    "    .drop(\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\")\n",
    "    rprmpf = rprmpf.groupBy('chdrnum','tranno','rskno','premcl').sum('cwp','cwc')\\\n",
    "    .withColumnRenamed('sum(cwp)','cwp')\\\n",
    "    .withColumnRenamed('sum(cwc)','cwc')\n",
    "\n",
    "    #MERGE GROSS AND CO-INSURANCE TABLES\n",
    "    combined = prempf.join(rprmpf, on=['chdrnum','tranno','rskno','premcl'], how='left').fillna(0, subset=['cwp','cwc'])\n",
    "    combined.cache()\n",
    "\n",
    "    \"\"\"\n",
    "    /* Now we do a small check (not needed each time) to see if the number\n",
    "       of rows in the original PREMPF containing the gross premium matches\n",
    "       at least with the new combined data. Hence the number of rows in\n",
    "       PREMPF should equal the new table COMBINED\t\t\t\t\t      */\n",
    "\n",
    "    /* Aggregate the Gross premium and commission on cdhrnum and tranno in\n",
    "       order to finally recon with ztrnpf \t\t\t\t\t\t\t\t  */\n",
    "    \"\"\"\n",
    "    #/* Since PREMPF is more granual than ZTRNPF, this aggregation should make it match with ZTRNPF\n",
    "    combined_sum = combined.groupBy('chdrnum','tranno').sum(\"gwp\",\"gwc\",\"cwp\",\"cwc\")\\\n",
    "    .withColumnRenamed('sum(gwp)','gwp')\\\n",
    "    .withColumnRenamed('sum(gwc)','gwc')\\\n",
    "    .withColumnRenamed('sum(cwp)','cwp')\\\n",
    "    .withColumnRenamed('sum(cwc)','cwc')\n",
    "\n",
    "    ##RECON ON GROSS SUB ACCOUNTS\n",
    "\n",
    "    #This table will contain all the information will be used in the next step\n",
    "    recon_pr_gr_psea_recon = df4.join(combined_sum, on=['chdrnum','tranno'], how='left').fillna(0, subset=['gwp','gwc','cwp','cwc'])\\\n",
    "    .filter( (abs(col('gwptotal')-col('gwp'))>0.01)|(abs(col('gwctotal')-col('gwc'))>0.01)|\n",
    "             (abs(col('cwptotal')-col('cwp'))>0.01)|(abs(col('cwctotal')-col('cwc'))>0.01) )\n",
    "\n",
    "    #This table will not contain the proportion info\n",
    "    recon_pr_gr_psea_recon.cache()\n",
    "    recon_pr_gr_psea_recon.write.parquet('{}recon_pr_gr_psea_recon.parquet'.format(output_folder))\n",
    "\n",
    "    #Creating the final premium table and we are reallocating the portion of  the data that did not match\n",
    "    recon = recon_pr_gr_psea_recon\\\n",
    "    .withColumn('propGWP',when( col('gwp')!=0, col('gwptotal')/col('gwp')).otherwise(0) )\\\n",
    "    .withColumn('propGWC',when( col('gwc')!=0, col('gwctotal')/col('gwc')).otherwise(0) )\\\n",
    "    .withColumn('propCWP',when( col('cwp')!=0, col('cwptotal')/col('cwp')).otherwise(0) )\\\n",
    "    .withColumn('propCWC',when( col('cwc')!=0, col('cwctotal')/col('cwc')).otherwise(0) )\n",
    "    recon_gr = recon[[\"chdrnum\",\"tranno\",\"propGWP\",\"propGWC\",\"propCWP\",\"propCWC\"]].withColumn('recon_exist', lit(True))\n",
    "\n",
    "    transv_pr_gr_psea = base_df.join(combined, on=['chdrnum', 'tranno'], how='inner').\\\n",
    "    join(recon_gr, on=['chdrnum', 'tranno'], how='left')\n",
    "\n",
    "    transv_pr_gr_psea = transv_pr_gr_psea\\\n",
    "    .withColumn('gwp', when(col('recon_exist')==True, round(col('gwp')*col('propGWP'),2) ).otherwise(col('gwp')) )\\\n",
    "    .withColumn('gwc', when(col('recon_exist')==True, round(col('gwc')*col('propGWC'),2) ).otherwise(col('gwc')) )\\\n",
    "    .withColumn('cwp', when(col('recon_exist')==True, round(col('cwp')*col('propCWP'),2) ).otherwise(col('cwp')) )\\\n",
    "    .withColumn('cwc', when(col('recon_exist')==True, round(col('cwc')*col('propCWC'),2) ).otherwise(col('cwc')) )\\\n",
    "    .drop(\"propGWP\",\"propGWC\",\"propCWP\",\"propCWC\",\"recon_exist\")\n",
    "\n",
    "    #The number of rows in the combination missmatch (between BASE and COMBINED) because we did not apply the same filters on COMBINED (such as the financial transactions)\n",
    "\n",
    "    transv_pr_gr_psea.write.parquet('{}transv_pr_gr_psea.parquet'.format(output_folder))\n",
    "\n",
    "    if monthend==1:\n",
    "\n",
    "        ztrnpf_rp1 = ztrnpf_rp.withColumnRenamed('rldgacct', 'chdrnum')\\\n",
    "                    .withColumnRenamed('accnum', 'accntid')\n",
    "\n",
    "        ztrnpf_rp2 = ztrnpf_rp1.withColumn('rwptotal', col('tranamt01') - col('tranamt03') )\\\n",
    "        .withColumn('rwctotal', col('tranamt04') + col('tranamt05') )\n",
    "\n",
    "        ztrnpf_rp3 = transformations(ztrnpf_rp2)\n",
    "\n",
    "        ztrnpf_ri = ztrnpf_rp3.groupBy('chdrnum','tranno','accntid').sum('rwptotal','rwctotal')\\\n",
    "        .withColumnRenamed('sum(rwptotal)','rwptotal')\\\n",
    "        .withColumnRenamed('sum(rwctotal)','rwctotal')\n",
    "\n",
    "        #GET DETAIL OF RE-INSURANCE TRANSACTIONS IN PREMPF_RP\n",
    "        rprmpf_ri = spark.read.parquet(rprmpf_rp_path)\\\n",
    "        [[\"chdrno\",\"rskno\",\"tranno\",\"premcl\",\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\",\"racc\",\"ritype\"]].filter(col('sacscode') == \"RP\")\n",
    "        rprmpf_ri = rprmpf_ri.withColumnRenamed('chdrno', 'chdrnum').withColumnRenamed('racc', 'accntid')\\\n",
    "        .withColumn('rwp',col('extr01')-col('extr03'))\\\n",
    "        .withColumn('rwc',col('extr04')+col('extr05'))\\\n",
    "        .drop(\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\")\n",
    "\n",
    "        #Re-insurance Premium information at a more granular level specifically by accntid AND ritype as well\n",
    "        rprmpf_ri = rprmpf_ri.groupBy('chdrnum','tranno','rskno','premcl','accntid','ritype').sum('rwp','rwc')\\\n",
    "        .withColumnRenamed('sum(rwp)','rwp')\\\n",
    "        .withColumnRenamed('sum(rwc)','rwc')\n",
    "\n",
    "        #Above table aggregated in the same way as before in order to reconcile with ZTRNPF_RI grouping\n",
    "        rprmpf_ri_sum = rprmpf_ri.groupBy('chdrnum','tranno','accntid').sum('rwp','rwc')\\\n",
    "        .withColumnRenamed('sum(rwp)','rwp')\\\n",
    "        .withColumnRenamed('sum(rwc)','rwc')\n",
    "\n",
    "        #RECON ON GROSS SUB ACCOUNTS\n",
    "        recon_pr_ri_psea_recon = ztrnpf_ri.join(rprmpf_ri_sum, on=['chdrnum','tranno','accntid'], how='left').fillna(0, subset=['rwp','rwc'])\\\n",
    "        .filter((abs(col('rwptotal')-col('rwp'))>0.01) | (abs(col('rwctotal')-col('rwc'))>0.01))\n",
    "\n",
    "        recon_pr_ri_psea_recon.write.parquet('{}recon_pr_ri_psea_recon.parquet'.format(output_folder))\n",
    "\n",
    "        recon_ri = recon_pr_ri_psea_recon\\\n",
    "        .withColumn('propRWP',when( col('rwp')!=0, col('rwptotal')/col('rwp')).otherwise(0) )\\\n",
    "        .withColumn('propRWC',when( col('rwc')!=0, col('rwctotal')/col('rwc')).otherwise(0) )\n",
    "\n",
    "        #Creating the final premium table and we are reallocating the portion of the data that did not match\n",
    "        recon_ri_subset = recon_ri[[\"chdrnum\",\"tranno\",\"propRWP\",\"propRWC\",\"accntid\"]].withColumn('recon_exist', lit(True))\\\n",
    "                            .withColumnRenamed('accntid','recon_accntid')\n",
    "\n",
    "        transv_pr_ri_psea = base_df.join(rprmpf_ri, on=['chdrnum', 'tranno'], how='inner').\\\n",
    "        join(recon_ri_subset, on=['chdrnum', 'tranno'], how='left') #ritype removed in RECON_RI \n",
    "\n",
    "        transv_pr_ri_psea = transv_pr_ri_psea\\\n",
    "        .withColumn('rwp', when(col('recon_exist')==True, round(col('rwp')*col('propRWP'),2) ).otherwise(col('rwp')) )\\\n",
    "        .withColumn('rwc', when(col('recon_exist')==True, round(col('rwc')*col('propRWC'),2) ).otherwise(col('rwc')) )\\\n",
    "        .drop(\"propRWP\",\"propRWC\")\n",
    "\n",
    "        transv_pr_ri_psea.write.parquet('{}transv_pr_ri_psea.parquet'.format(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "ztrnpf_path = '/group/axa_malaysia/data/adm_ztrnpf'\n",
    "prempf_path = '/group/axa_malaysia/data/adm_prempf'\n",
    "rprmpf_co_path = '/group/axa_malaysia/data/adm_rprmpf_co'\n",
    "rprmpf_rp_path = '/group/axa_malaysia/data/adm_rprmpf_rp'\n",
    "monthend = 1\n",
    "PREMIUM_PSEA(adm_mapping_path,ztrnpf_path,prempf_path,rprmpf_co_path,rprmpf_rp_path,monthend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33616782"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(r'/user/cchin/data/sas_402/transv_pr_gr_psea.parquet').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34646234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(r'/user/cchin/data/sas_402/transv_pr_ri_psea.parquet').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(r'/user/cchin/data/sas_402/recon_pr_gr_psea_recon.parquet').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.read.parquet(r'/user/cchin/data/sas_402/recon_pr_ri_psea_recon.parquet').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas.core.indexes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a152e704c7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpr_gr_psea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pr_gr_psea.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'pandas.core.indexes'"
     ]
    }
   ],
   "source": [
    "pr_gr_psea = pickle.load(open('pr_gr_psea.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_gr_psea = spark.read.csv('pr_gr_psea.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "|chdrnum|BATCBRN|BATCTRCDE|TRANNO|CHDRSTCDC|agentid|yrm|d_tran|d_eff|d_com|d_exp|trantype|RSKNO|PREMCL|gwp|gwc|cwp|cwc|\n",
      "+-------+-------+---------+------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "+-------+-------+---------+------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr_gr_psea.filter(col('chdrnum')=='01141394').show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "|chdrnum|tranno|agentid|batctrcde|chdrstcdc|batcbrn|yrm|d_tran|d_eff|d_com|d_exp|trantype|rskno|premcl|gwp|gwc|cwp|cwc|\n",
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transv_pr_gr_psea.filter(col('chdrnum')=='01141394').show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transv_pr_gr_psea = spark.read.parquet(r'/user/cchin/data/sas_402/transv_pr_gr_psea.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chdrpf = spark.read.parquet(r'/group/axa_malaysia/data/adm_chdrpf')\n",
    "ztrnpf = spark.read.parquet(r'/group/axa_malaysia/data/adm_ztrnpf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+--------+-------+------+---------+--------+------+--------+---------+--------+--------+--------+------+------+-------+-------+-------+------+--------+---------+-------+-------+--------+--------+---------+---------+------+-----+------+-------+------+-------+------+------+--------+--------------------+\n",
      "|CHDRPFX|CHDRCOY| CHDRNUM|SERVUNIT|CNTTYPE|TRANNO|VALIDFLAG|CURRFROM|CURRTO|STATCODE|STATREASN|STATDATE|STATTRAN| OCCDATE|CCDATE|CRDATE|RNLTYPE|RNLDURN|REPTYPE|REPNUM| COWNNUM|CNTBRANCH|AGNTNUM|PAYPLAN|CAMPAIGN|NOFRISKS|CHDRSTCDA|CHDRSTCDC|MPLNUM|COPPN|COTYPE|COVERNT|DTECAN|QUOTENO|ZRENNO|ZENDNO|ZREPOLNO|              datime|\n",
      "+-------+-------+--------+--------+-------+------+---------+--------+------+--------+---------+--------+--------+--------+------+------+-------+-------+-------+------+--------+---------+-------+-------+--------+--------+---------+---------+------+-----+------+-------+------+-------+------+------+--------+--------------------+\n",
      "|     CH|      1|04177419|      GP|    SME|     2|        1|       0|     0|      IF|         |       0|       0|20170513|     0|     0|       |      0|       |      |07449895|         |       |       |        |       0|         |         |      |  0.0|      |       |     0|       |     0|     0|        |2017-06-22 11:28:...|\n",
      "+-------+-------+--------+--------+-------+------+---------+--------+------+--------+---------+--------+--------+--------+------+------+-------+-------+-------+------+--------+---------+-------+-------+--------+--------+---------+---------+------+-----+------+-------+------+-------+------+------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chdrpf.filter(col('chdrnum')=='04177419').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01141394',\n",
       " '01150395',\n",
       " '01157348',\n",
       " '01158389',\n",
       " '01163859',\n",
       " '01179543',\n",
       " '01184372',\n",
       " '01305843',\n",
       " '01305848',\n",
       " '01305860']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"01141394\n",
    "01150395\n",
    "01157348\n",
    "01158389\n",
    "01163859\n",
    "01179543\n",
    "01184372\n",
    "01305843\n",
    "01305848\n",
    "01305860\"\"\".splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|BATCTRCDE|\n",
      "+---------+\n",
      "|     T922|\n",
      "|     BR9A|\n",
      "|     T933|\n",
      "|     T928|\n",
      "|     T903|\n",
      "|     T926|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ztrnpf.filter(col('RLDGACCT').isin(['01141394',\n",
    " '01150395',\n",
    " '01157348',\n",
    " '01158389',\n",
    " '01163859',\n",
    " '01179543',\n",
    " '01184372',\n",
    " '01305843',\n",
    " '01305848',\n",
    " '01305860']))[['BATCTRCDE']].distinct().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "ztrnpf_path = '/group/axa_malaysia/data/adm_ztrnpf'\n",
    "prempf_path = '/group/axa_malaysia/data/adm_prempf'\n",
    "rprmpf_co_path = '/group/axa_malaysia/data/adm_rprmpf_co'\n",
    "rprmpf_rp_path = '/group/axa_malaysia/data/adm_rprmpf_rp'\n",
    "monthend = 1\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "def format_date(strdate):\n",
    "    try: \n",
    "        return datetime.strptime(str(strdate),'%Y%m%d').strftime('%Y-%m-%d')\n",
    "    except: \n",
    "        return '2999-12-31'\n",
    "_format_date = udf(format_date,StringType())\n",
    "\n",
    "\"\"\"\n",
    "    /* 1) sacscode filter */\n",
    "    /* Consider Gross Prem (FG) and Co-insurance Prem      */\n",
    "    /* we will consider RP (Re-insurance premium) in  \t   */\n",
    "    /* the next section, since it only needs to run   \t   */\n",
    "    /* once a month - it is a massive table\t\t\t       */\n",
    "    /* 2) batctrcde filter */\n",
    "    /* Only consider real financial transactions      \t   */\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    /* Map Transaction Types */\n",
    "    /* Note - the mapping is limited to the filter, so the mapping is only needed for the\n",
    "       transaction types applied in the filter */\n",
    "    Transaction Types are read from the excel mapping files\n",
    "\"\"\"\n",
    "transtype_map = pd.read_excel(adm_mapping_path, sheetname='300').set_index('batctrcde').to_dict()['trantype']\n",
    "transtype_map_bc = sc.broadcast(transtype_map)\n",
    "\n",
    "ztrnpf = spark.read.parquet(ztrnpf_path)[['batcactyr',\n",
    " 'batcactmn',\n",
    " 'rldgacct',\n",
    " 'tranno',\n",
    " 'ccdate',\n",
    " 'effdate',\n",
    " 'accnum',\n",
    " 'expiry_date',\n",
    " 'batctrcde',\n",
    " 'sacscode',\n",
    " 'trandate',\n",
    " 'chdrstcdc',\n",
    " 'tranamt01',\n",
    " 'tranamt02',\n",
    " 'tranamt03',\n",
    " 'tranamt04',\n",
    " 'tranamt05',\n",
    " 'batcbrn']].filter( col(\"batctrcde\").isin(['T409','T44B','T922','T405','T903','T413','T927','T928']) )#.limit(100000)\n",
    "ztrnpf_fgco = ztrnpf\n",
    "\"\"\"\n",
    "ztrnpf_fgco = ztrnpf.filter(col(\"sacscode\").isin(\"FG\",\"CO\"))\n",
    "ztrnpf_rp = ztrnpf.filter(col(\"sacscode\")=='RP')\n",
    "\"\"\"\n",
    "def transformations(df):\n",
    "    df = df.withColumn('yrm', col('batcactyr')*100+col('batcactmn'))\n",
    "\n",
    "    #dates formatting\n",
    "    df = df.withColumn('d_tran', to_date(_format_date(col('trandate'))))\\\n",
    "    .withColumn('d_eff', to_date(_format_date(col('effdate'))))\\\n",
    "    .withColumn('d_com', to_date(_format_date(col('ccdate'))))\\\n",
    "    .withColumn('d_exp', to_date(_format_date(col('expiry_date'))))\n",
    "\n",
    "    df = df.drop('batcactyr','batcactmn','effdate','ccdate','expiry_date','trandate','tranamt01','tranamt02','tranamt03','tranamt04','tranamt05')\n",
    "\n",
    "    #map transaction types\n",
    "    df = df.withColumn('trantype', udf(lambda x: transtype_map_bc.value[x])(col('batctrcde')))\n",
    "    return df\n",
    "\n",
    "df1 = ztrnpf_fgco.withColumnRenamed('rldgacct', 'chdrnum')\\\n",
    "            .withColumnRenamed('accnum', 'agentid')\n",
    "\n",
    "df2 = df1.withColumn('gwptotal', when(col('sacscode')=='FG', col('tranamt01') - col('tranamt03') ).otherwise(lit(0)) )\\\n",
    ".withColumn('gwctotal', when(col('sacscode')=='FG', col('tranamt04') + col('tranamt05') ).otherwise(lit(0)) )\\\n",
    ".withColumn('cwptotal', when(col('sacscode')!='FG', col('tranamt01') - col('tranamt03') ).otherwise(lit(0)) )\\\n",
    ".withColumn('cwctotal', when(col('sacscode')!='FG', col('tranamt04') + col('tranamt05') ).otherwise(lit(0)) )\n",
    "\n",
    "df3 = transformations(df2)\n",
    "\n",
    "#FIRST GET BASE\n",
    "base_df = df3.drop('gwptotal','gwctotal','cwptotal','cwctotal','sacscode').\\\n",
    "sort('chdrnum', 'tranno').dropDuplicates(subset=['chdrnum', 'tranno'])\n",
    "base_df.cache()\n",
    "\"\"\"\n",
    "#FIRST GET BASE\n",
    "base_df = df3.filter(col('sacscode')=='FG').drop('gwptotal','gwctotal','cwptotal','cwctotal','sacscode').\\\n",
    "sort('chdrnum', 'tranno').dropDuplicates(subset=['chdrnum', 'tranno'])\n",
    "base_df.cache()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"THEN AGGREGATE ZTRNPF\n",
    "    /* ****************************************************************** */\n",
    "    /* Sums gwptotal gwctotal cwptotal cwctotal by chdrnum and tranno     */\n",
    "    /* Since we took only FG transactions the filter is already leaving only one unique chdrnum and tranno combination, \n",
    "    this aggregation mainly used to ensure that there are only one combination.         */\n",
    "    /* ****************************************************************** */\n",
    "\"\"\"\n",
    "df4 = df3.groupBy('chdrnum','tranno').sum('gwptotal','gwctotal','cwptotal','cwctotal')\\\n",
    ".withColumnRenamed('sum(gwptotal)','gwptotal')\\\n",
    ".withColumnRenamed('sum(gwctotal)','gwctotal')\\\n",
    ".withColumnRenamed('sum(cwptotal)','cwptotal')\\\n",
    ".withColumnRenamed('sum(cwctotal)','cwctotal')\n",
    "\n",
    "#GET DETAIL OF GROSS TRANSACTIONS IN PREMPF\n",
    "prempf = spark.read.parquet(prempf_path)[[\"chdrno\",\"rskno\",\"tranno\",\"premcl\",\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\"]]\n",
    "prempf = prempf.withColumnRenamed('chdrno', 'chdrnum')\\\n",
    ".withColumn('gwp',col('extr01')-col('extr03'))\\\n",
    ".withColumn('gwc',col('extr04')+col('extr05'))\\\n",
    ".drop(\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\")\n",
    "prempf = prempf.groupBy('chdrnum','tranno','rskno','premcl').sum('gwp','gwc')\\\n",
    ".withColumnRenamed('sum(gwp)','gwp')\\\n",
    ".withColumnRenamed('sum(gwc)','gwc')\n",
    "\n",
    "#GET DETAIL OF CO-INSURANCE TRANSACTIONS IN RPRMPF_CO\n",
    "rprmpf = spark.read.parquet(rprmpf_co_path)\\\n",
    "[[\"chdrno\",\"rskno\",\"tranno\",\"premcl\",\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\"]].filter(col('sacscode') == \"CO\")\n",
    "rprmpf = rprmpf.withColumnRenamed('chdrno', 'chdrnum')\\\n",
    ".withColumn('cwp',col('extr01')-col('extr03'))\\\n",
    ".withColumn('cwc',col('extr04')+col('extr05'))\\\n",
    ".drop(\"extr01\",\"extr02\",\"extr03\",\"extr04\",\"extr05\")\n",
    "rprmpf = rprmpf.groupBy('chdrnum','tranno','rskno','premcl').sum('cwp','cwc')\\\n",
    ".withColumnRenamed('sum(cwp)','cwp')\\\n",
    ".withColumnRenamed('sum(cwc)','cwc')\n",
    "\n",
    "#MERGE GROSS AND CO-INSURANCE TABLES\n",
    "combined = prempf.join(rprmpf, on=['chdrnum','tranno','rskno','premcl'], how='left').fillna(0, subset=['cwp','cwc'])\n",
    "combined.cache()\n",
    "\n",
    "\"\"\"\n",
    "/* Now we do a small check (not needed each time) to see if the number\n",
    "   of rows in the original PREMPF containing the gross premium matches\n",
    "   at least with the new combined data. Hence the number of rows in\n",
    "   PREMPF should equal the new table COMBINED\t\t\t\t\t      */\n",
    "\n",
    "/* Aggregate the Gross premium and commission on cdhrnum and tranno in\n",
    "   order to finally recon with ztrnpf \t\t\t\t\t\t\t\t  */\n",
    "\"\"\"\n",
    "#/* Since PREMPF is more granual than ZTRNPF, this aggregation should make it match with ZTRNPF\n",
    "combined_sum = combined.groupBy('chdrnum','tranno').sum(\"gwp\",\"gwc\",\"cwp\",\"cwc\")\\\n",
    ".withColumnRenamed('sum(gwp)','gwp')\\\n",
    ".withColumnRenamed('sum(gwc)','gwc')\\\n",
    ".withColumnRenamed('sum(cwp)','cwp')\\\n",
    ".withColumnRenamed('sum(cwc)','cwc')\n",
    "\n",
    "##RECON ON GROSS SUB ACCOUNTS\n",
    "\n",
    "#This table will contain all the information will be used in the next step\n",
    "recon_pr_gr_psea_recon = df4.join(combined_sum, on=['chdrnum','tranno'], how='left').fillna(0, subset=['gwp','gwc','cwp','cwc'])\\\n",
    ".filter( (abs(col('gwptotal')-col('gwp'))>0.01)|(abs(col('gwctotal')-col('gwc'))>0.01)|\n",
    "         (abs(col('cwptotal')-col('cwp'))>0.01)|(abs(col('cwctotal')-col('cwc'))>0.01) )\n",
    "\n",
    "#This table will not contain the proportion info\n",
    "recon_pr_gr_psea_recon.cache()\n",
    "\n",
    "#Creating the final premium table and we are reallocating the portion of  the data that did not match\n",
    "recon = recon_pr_gr_psea_recon\\\n",
    ".withColumn('propGWP',when( col('gwp')!=0, col('gwptotal')/col('gwp')).otherwise(0) )\\\n",
    ".withColumn('propGWC',when( col('gwc')!=0, col('gwctotal')/col('gwc')).otherwise(0) )\\\n",
    ".withColumn('propCWP',when( col('cwp')!=0, col('cwptotal')/col('cwp')).otherwise(0) )\\\n",
    ".withColumn('propCWC',when( col('cwc')!=0, col('cwctotal')/col('cwc')).otherwise(0) )\n",
    "recon_gr = recon[[\"chdrnum\",\"tranno\",\"propGWP\",\"propGWC\",\"propCWP\",\"propCWC\"]].withColumn('recon_exist', lit(True))\n",
    "\n",
    "transv_pr_gr_psea = base_df.join(combined, on=['chdrnum', 'tranno'], how='inner').\\\n",
    "join(recon_gr, on=['chdrnum', 'tranno'], how='left')\n",
    "\n",
    "transv_pr_gr_psea = transv_pr_gr_psea\\\n",
    ".withColumn('gwp', when(col('recon_exist')==True, round(col('gwp')*col('propGWP'),2) ).otherwise(col('gwp')) )\\\n",
    ".withColumn('gwc', when(col('recon_exist')==True, round(col('gwc')*col('propGWC'),2) ).otherwise(col('gwc')) )\\\n",
    ".withColumn('cwp', when(col('recon_exist')==True, round(col('cwp')*col('propCWP'),2) ).otherwise(col('cwp')) )\\\n",
    ".withColumn('cwc', when(col('recon_exist')==True, round(col('cwc')*col('propCWC'),2) ).otherwise(col('cwc')) )\\\n",
    ".drop(\"propGWP\",\"propGWC\",\"propCWP\",\"propCWC\",\"recon_exist\")\n",
    "\n",
    "#The number of rows in the combination missmatch (between BASE and COMBINED) because we did not apply the same filters on COMBINED (such as the financial transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalArgumentException: java.net.UnknownHostException: laphdpmtr03.asia.bigdata.intraxa;laphdpmtr04.asia.bigdata.intraxa\n\tat org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.getDelegationTokenService(KMSClientProvider.java:823)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.addDelegationTokens(KMSClientProvider.java:779)\n\tat org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension.addDelegationTokens(KeyProviderDelegationTokenExtension.java:86)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.addDelegationTokens(DistributedFileSystem.java:2046)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider$$anonfun$obtainCredentials$2.apply(HDFSCredentialProvider.scala:50)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider$$anonfun$obtainCredentials$2.apply(HDFSCredentialProvider.scala:47)\n\tat scala.collection.immutable.Set$Set1.foreach(Set.scala:94)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider.obtainCredentials(HDFSCredentialProvider.scala:47)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:82)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:80)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager.obtainCredentials(ConfigurableCredentialManager.scala:80)\n\tat org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:403)\n\tat org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:882)\n\tat org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:171)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56)\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:156)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:509)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.net.UnknownHostException: laphdpmtr03.asia.bigdata.intraxa;laphdpmtr04.asia.bigdata.intraxa\n\t... 37 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-acc5346f16c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'2999-12-31'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0m_format_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStringType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \"\"\"\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mudf\u001b[1;34m(f, returnType)\u001b[0m\n\u001b[0;32m   1870\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1871\u001b[0m     \"\"\"\n\u001b[1;32m-> 1872\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUserDefinedFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1874\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'map'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'since'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore_unicode_prefix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, returnType, name)\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_broadcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1830\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_create_judf\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1834\u001b[1;33m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1835\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m--> 118\u001b[1;33m                           conf, jsc, profiler_cls)\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36m_initialize_context\u001b[1;34m(self, jconf)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mInitialize\u001b[0m \u001b[0mSparkContext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0minitialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1399\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1401\u001b[1;33m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalArgumentException: java.net.UnknownHostException: laphdpmtr03.asia.bigdata.intraxa;laphdpmtr04.asia.bigdata.intraxa\n\tat org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.getDelegationTokenService(KMSClientProvider.java:823)\n\tat org.apache.hadoop.crypto.key.kms.KMSClientProvider.addDelegationTokens(KMSClientProvider.java:779)\n\tat org.apache.hadoop.crypto.key.KeyProviderDelegationTokenExtension.addDelegationTokens(KeyProviderDelegationTokenExtension.java:86)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.addDelegationTokens(DistributedFileSystem.java:2046)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider$$anonfun$obtainCredentials$2.apply(HDFSCredentialProvider.scala:50)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider$$anonfun$obtainCredentials$2.apply(HDFSCredentialProvider.scala:47)\n\tat scala.collection.immutable.Set$Set1.foreach(Set.scala:94)\n\tat org.apache.spark.deploy.yarn.security.HDFSCredentialProvider.obtainCredentials(HDFSCredentialProvider.scala:47)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:82)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:80)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)\n\tat org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager.obtainCredentials(ConfigurableCredentialManager.scala:80)\n\tat org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:403)\n\tat org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:882)\n\tat org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:171)\n\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56)\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:156)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:509)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:236)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.net.UnknownHostException: laphdpmtr03.asia.bigdata.intraxa;laphdpmtr04.asia.bigdata.intraxa\n\t... 37 more\n"
     ]
    }
   ],
   "source": [
    "adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "ztrnpf_path = '/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04'\n",
    "prempf_path = '/river/axa_my/axa_aaro_psea/data/psea_prempf/merge/yyyy=2017/mm=11/dd=04'\n",
    "rprmpf_path = '/river/axa_my/axa_aaro_psea/data/psea_rprmpf/merge/yyyy=2017/mm=11/dd=04'\n",
    "monthend = 1\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "def format_date(strdate):\n",
    "    try: \n",
    "        return datetime.strptime(str(strdate),'%Y%m%d').strftime('%Y-%m-%d')\n",
    "    except: \n",
    "        return '2999-12-31'\n",
    "_format_date = udf(format_date,StringType())\n",
    "\n",
    "\"\"\"\n",
    "    /* 1) sacscode filter */\n",
    "    /* Consider Gross Prem (FG) and Co-insurance Prem      */\n",
    "    /* we will consider RP (Re-insurance premium) in  \t   */\n",
    "    /* the next section, since it only needs to run   \t   */\n",
    "    /* once a month - it is a massive table\t\t\t       */\n",
    "    /* 2) batctrcde filter */\n",
    "    /* Only consider real financial transactions      \t   */\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    /* Map Transaction Types */\n",
    "    /* Note - the mapping is limited to the filter, so the mapping is only needed for the\n",
    "       transaction types applied in the filter */\n",
    "    Transaction Types are read from the excel mapping files\n",
    "\"\"\"\n",
    "transtype_map = pd.read_excel(adm_mapping_path, sheetname='300').set_index('batctrcde').to_dict()['trantype']\n",
    "transtype_map_bc = sc.broadcast(transtype_map)\n",
    "\n",
    "ztrnpf = spark.read.parquet(ztrnpf_path)[['batcactyr',\n",
    " 'batcactmn',\n",
    " 'rldgacct',\n",
    " 'tranno',\n",
    " 'ccdate',\n",
    " 'effdate',\n",
    " 'accnum',\n",
    " 'expiry_date',\n",
    " 'batctrcde',\n",
    " 'sacscode',\n",
    " 'trandate',\n",
    " 'chdrstcdc',\n",
    " 'tranamt01',\n",
    " 'tranamt02',\n",
    " 'tranamt03',\n",
    " 'tranamt04',\n",
    " 'tranamt05',\n",
    " 'tranamt14',\n",
    " 'batcbrn']].filter( col(\"batctrcde\").isin(['TA39','T409','T44B','T922','T405','T903','T413','T927','T928',\n",
    "                                            'BA25','T454','T467','T913','T914','T926','T930','T934','T931']) )#.limit(100000)\n",
    "#'B470','T46B','T475','T840','B920','BR9A','T8A0','T933'\n",
    "ztrnpf_fgco = ztrnpf\n",
    "\"\"\"\n",
    "ztrnpf_fgco = ztrnpf.filter(col(\"sacscode\").isin(\"FG\",\"CO\"))\n",
    "ztrnpf_rp = ztrnpf.filter(col(\"sacscode\")=='RP')\n",
    "\"\"\"\n",
    "def transformations(df):\n",
    "    df = df.withColumn('yrm', col('batcactyr')*100+col('batcactmn'))\n",
    "\n",
    "    #dates formatting\n",
    "    df = df.withColumn('d_tran', to_date(_format_date(col('trandate'))))\\\n",
    "    .withColumn('d_eff', to_date(_format_date(col('effdate'))))\\\n",
    "    .withColumn('d_com', to_date(_format_date(col('ccdate'))))\\\n",
    "    .withColumn('d_exp', to_date(_format_date(col('expiry_date'))))\n",
    "\n",
    "    df = df.drop('batcactyr','batcactmn','effdate','ccdate','expiry_date','trandate','tranamt01','tranamt02','tranamt03','tranamt04',\n",
    "                 'tranamt05','tranamt14')\n",
    "\n",
    "    #map transaction types\n",
    "    df = df.withColumn('trantype', udf(lambda x: transtype_map_bc.value.get(x,'NA'))(col('batctrcde')))\n",
    "    return df\n",
    "\n",
    "df1 = ztrnpf.withColumnRenamed('rldgacct', 'chdrnum')\\\n",
    "            .withColumnRenamed('accnum', 'agentid')\n",
    "\n",
    "df2 = df1.withColumn('fg_premium_total', when(col('sacscode')=='FG', col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('fg_commission_total', when(col('sacscode')=='FG', col('tranamt04') + col('tranamt05')).otherwise(0) )\\\n",
    ".withColumn('co_premium_total', when(col('sacscode')=='CO', col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('co_commission_total', when(col('sacscode')=='CO', col('tranamt04') + col('tranamt05')).otherwise(0) )\\\n",
    ".withColumn('rp_premium_total', when(col('sacscode')=='RP', col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('rp_commission_total', when(col('sacscode')=='RP', col('tranamt04') + col('tranamt05')).otherwise(0) )\n",
    "\n",
    "df3 = transformations(df2)\n",
    "\n",
    "df4 = df3.groupBy('chdrnum','tranno', 'batcbrn', 'yrm').sum('fg_premium_total',\n",
    "                                          'fg_commission_total',\n",
    "                                          'co_premium_total',\n",
    "                                          'co_commission_total',\n",
    "                                          'rp_premium_total',\n",
    "                                          'rp_commission_total')\\\n",
    ".withColumnRenamed('sum(fg_premium_total)','fg_premium_total')\\\n",
    ".withColumnRenamed('sum(fg_commission_total)','fg_commission_total')\\\n",
    ".withColumnRenamed('sum(co_premium_total)','co_premium_total')\\\n",
    ".withColumnRenamed('sum(co_commission_total)','co_commission_total')\\\n",
    ".withColumnRenamed('sum(rp_premium_total)','rp_premium_total')\\\n",
    ".withColumnRenamed('sum(rp_commission_total)','rp_commission_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`d_tran`' given input columns: [fg_commission_total, fg_premium_total, rp_premium_total, tranno, co_premium_total, rp_commission_total, co_commission_total, chdrnum];;\\n'Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, rp_commission_total#820, cast('d_tran as string) AS d_tran#830]\\n+- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, sum(rp_commission_total)#760 AS rp_commission_total#820]\\n   +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, sum(rp_premium_total)#759 AS rp_premium_total#810, sum(rp_commission_total)#760]\\n      +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, sum(co_commission_total)#758 AS co_commission_total#800, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n         +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, sum(co_premium_total)#757 AS co_premium_total#790, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n            +- Project [chdrnum#350, tranno#16, fg_premium_total#770, sum(fg_commission_total)#756 AS fg_commission_total#780, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n               +- Project [chdrnum#350, tranno#16, sum(fg_premium_total)#755 AS fg_premium_total#770, sum(fg_commission_total)#756, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n                  +- Aggregate [chdrnum#350, tranno#16], [chdrnum#350, tranno#16, sum(fg_premium_total#392) AS sum(fg_premium_total)#755, sum(fg_commission_total#414) AS sum(fg_commission_total)#756, sum(co_premium_total#437) AS sum(co_premium_total)#757, sum(co_commission_total#461) AS sum(co_commission_total)#758, sum(rp_premium_total#486) AS sum(rp_premium_total)#759, sum(rp_commission_total#512) AS sum(rp_commission_total)#760]\\n                     +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657, <lambda>(batctrcde#7) AS trantype#708]\\n                        +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657]\\n                           +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 6 more fields]\\n                              +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 5 more fields]\\n                                 +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 4 more fields]\\n                                    +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 3 more fields]\\n                                       +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 2 more fields]\\n                                          +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_commission_total#512]\\n                                             +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_premium_total#486]\\n                                                +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_commission_total#461]\\n                                                   +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_premium_total#437]\\n                                                      +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_commission_total#414]\\n                                                         +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_premium_total#392]\\n                                                            +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138 AS agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                               +- Project [batcactyr#5, batcactmn#6, rldgacct#11 AS chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                                  +- Filter batctrcde#7 IN (TA39,T409,T44B,T922,T405,T903,T413,T927,T928,BA25,T454,T467,T913,T914,T926,T930,T934,B470,T46B,T475,T840,B920,BR9A,T8A0,T931,T933)\\n                                                                     +- Project [batcactyr#5, batcactmn#6, rldgacct#11, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                                        +- Relation[rrn#0,ci_action#1,batcpfx#2,batccoy#3,batcbrn#4,batcactyr#5,batcactmn#6,batctrcde#7,batcbatch#8,rldgpfx#9,rldgcoy#10,rldgacct#11,origcurr#12,acctcurr#13,crate#14,cnttype#15,tranno#16,cntbranch#17,chdrstcda#18,chdrstcdb#19,chdrstcdc#20,chdrstcdd#21,chdrstcde#22,postmonth#23,... 140 more fields] parquet\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o232.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`d_tran`' given input columns: [fg_commission_total, fg_premium_total, rp_premium_total, tranno, co_premium_total, rp_commission_total, co_commission_total, chdrnum];;\n'Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, rp_commission_total#820, cast('d_tran as string) AS d_tran#830]\n+- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, sum(rp_commission_total)#760 AS rp_commission_total#820]\n   +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, sum(rp_premium_total)#759 AS rp_premium_total#810, sum(rp_commission_total)#760]\n      +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, sum(co_commission_total)#758 AS co_commission_total#800, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\n         +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, sum(co_premium_total)#757 AS co_premium_total#790, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\n            +- Project [chdrnum#350, tranno#16, fg_premium_total#770, sum(fg_commission_total)#756 AS fg_commission_total#780, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\n               +- Project [chdrnum#350, tranno#16, sum(fg_premium_total)#755 AS fg_premium_total#770, sum(fg_commission_total)#756, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\n                  +- Aggregate [chdrnum#350, tranno#16], [chdrnum#350, tranno#16, sum(fg_premium_total#392) AS sum(fg_premium_total)#755, sum(fg_commission_total#414) AS sum(fg_commission_total)#756, sum(co_premium_total#437) AS sum(co_premium_total)#757, sum(co_commission_total#461) AS sum(co_commission_total)#758, sum(rp_premium_total#486) AS sum(rp_premium_total)#759, sum(rp_commission_total#512) AS sum(rp_commission_total)#760]\n                     +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657, <lambda>(batctrcde#7) AS trantype#708]\n                        +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657]\n                           +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 6 more fields]\n                              +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 5 more fields]\n                                 +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 4 more fields]\n                                    +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 3 more fields]\n                                       +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 2 more fields]\n                                          +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_commission_total#512]\n                                             +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_premium_total#486]\n                                                +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_commission_total#461]\n                                                   +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_premium_total#437]\n                                                      +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_commission_total#414]\n                                                         +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_premium_total#392]\n                                                            +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138 AS agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\n                                                               +- Project [batcactyr#5, batcactmn#6, rldgacct#11 AS chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\n                                                                  +- Filter batctrcde#7 IN (TA39,T409,T44B,T922,T405,T903,T413,T927,T928,BA25,T454,T467,T913,T914,T926,T930,T934,B470,T46B,T475,T840,B920,BR9A,T8A0,T931,T933)\n                                                                     +- Project [batcactyr#5, batcactmn#6, rldgacct#11, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\n                                                                        +- Relation[rrn#0,ci_action#1,batcpfx#2,batccoy#3,batcbrn#4,batcactyr#5,batcactmn#6,batctrcde#7,batcbatch#8,rldgpfx#9,rldgcoy#10,rldgacct#11,origcurr#12,acctcurr#13,crate#14,cnttype#15,tranno#16,cntbranch#17,chdrstcda#18,chdrstcdb#19,chdrstcdc#20,chdrstcdd#21,chdrstcde#22,postmonth#23,... 140 more fields] parquet\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:266)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:280)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:280)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$6.apply(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2845)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1131)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:1884)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-090327da00dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_tran'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_tran'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_eff'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_eff'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_com'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_com'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_exp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd_exp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   1500\u001b[0m         \"\"\"\n\u001b[0;32m   1501\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col should be Column\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cchin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: \"cannot resolve '`d_tran`' given input columns: [fg_commission_total, fg_premium_total, rp_premium_total, tranno, co_premium_total, rp_commission_total, co_commission_total, chdrnum];;\\n'Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, rp_commission_total#820, cast('d_tran as string) AS d_tran#830]\\n+- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, rp_premium_total#810, sum(rp_commission_total)#760 AS rp_commission_total#820]\\n   +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, co_commission_total#800, sum(rp_premium_total)#759 AS rp_premium_total#810, sum(rp_commission_total)#760]\\n      +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, co_premium_total#790, sum(co_commission_total)#758 AS co_commission_total#800, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n         +- Project [chdrnum#350, tranno#16, fg_premium_total#770, fg_commission_total#780, sum(co_premium_total)#757 AS co_premium_total#790, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n            +- Project [chdrnum#350, tranno#16, fg_premium_total#770, sum(fg_commission_total)#756 AS fg_commission_total#780, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n               +- Project [chdrnum#350, tranno#16, sum(fg_premium_total)#755 AS fg_premium_total#770, sum(fg_commission_total)#756, sum(co_premium_total)#757, sum(co_commission_total)#758, sum(rp_premium_total)#759, sum(rp_commission_total)#760]\\n                  +- Aggregate [chdrnum#350, tranno#16], [chdrnum#350, tranno#16, sum(fg_premium_total#392) AS sum(fg_premium_total)#755, sum(fg_commission_total#414) AS sum(fg_commission_total)#756, sum(co_premium_total#437) AS sum(co_premium_total)#757, sum(co_commission_total#461) AS sum(co_commission_total)#758, sum(rp_premium_total#486) AS sum(rp_premium_total)#759, sum(rp_commission_total#512) AS sum(rp_commission_total)#760]\\n                     +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657, <lambda>(batctrcde#7) AS trantype#708]\\n                        +- Project [chdrnum#350, tranno#16, agentid#371, batctrcde#7, sacscode#28, chdrstcdc#20, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, rp_commission_total#512, yrm#539, d_tran#567, d_eff#596, d_com#626, d_exp#657]\\n                           +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 6 more fields]\\n                              +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 5 more fields]\\n                                 +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 4 more fields]\\n                                    +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 3 more fields]\\n                                       +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, ... 2 more fields]\\n                                          +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, rp_premium_total#486, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_commission_total#512]\\n                                             +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, co_commission_total#461, CASE WHEN (sacscode#28 = RP) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS rp_premium_total#486]\\n                                                +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, co_premium_total#437, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_commission_total#461]\\n                                                   +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, fg_commission_total#414, CASE WHEN (sacscode#28 = CO) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS co_premium_total#437]\\n                                                      +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, fg_premium_total#392, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(tranamt04#58 as decimal(18,2))) + promote_precision(cast(tranamt05#59 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_commission_total#414]\\n                                                         +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4, CASE WHEN (sacscode#28 = FG) THEN CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(tranamt01#55 as decimal(18,2))) - promote_precision(cast(tranamt03#57 as decimal(18,2)))), DecimalType(18,2)) as decimal(18,2))) + promote_precision(cast(tranamt14#68 as decimal(18,2)))), DecimalType(18,2)) ELSE cast(0 as decimal(18,2)) END AS fg_premium_total#392]\\n                                                            +- Project [batcactyr#5, batcactmn#6, chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138 AS agentid#371, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                               +- Project [batcactyr#5, batcactmn#6, rldgacct#11 AS chdrnum#350, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                                  +- Filter batctrcde#7 IN (TA39,T409,T44B,T922,T405,T903,T413,T927,T928,BA25,T454,T467,T913,T914,T926,T930,T934,B470,T46B,T475,T840,B920,BR9A,T8A0,T931,T933)\\n                                                                     +- Project [batcactyr#5, batcactmn#6, rldgacct#11, tranno#16, ccdate#139, effdate#27, accnum#138, expiry_date#140, batctrcde#7, sacscode#28, trandate#25, chdrstcdc#20, tranamt01#55, tranamt02#56, tranamt03#57, tranamt04#58, tranamt05#59, tranamt14#68, batcbrn#4]\\n                                                                        +- Relation[rrn#0,ci_action#1,batcpfx#2,batccoy#3,batcbrn#4,batcactyr#5,batcactmn#6,batctrcde#7,batcbatch#8,rldgpfx#9,rldgcoy#10,rldgacct#11,origcurr#12,acctcurr#13,crate#14,cnttype#15,tranno#16,cntbranch#17,chdrstcda#18,chdrstcdb#19,chdrstcdc#20,chdrstcdd#21,chdrstcde#22,postmonth#23,... 140 more fields] parquet\\n\""
     ]
    }
   ],
   "source": [
    "df4 = df4.withColumn('d_tran', col('d_tran').cast('string'))\\\n",
    ".withColumn('d_eff', col('d_eff').cast('string'))\\\n",
    ".withColumn('d_com', col('d_com').cast('string'))\\\n",
    ".withColumn('d_exp', col('d_exp').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34860276"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/ztrnpf').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36006855"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/adm_ztrnpf').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|RLDGACCT|count|\n",
      "+--------+-----+\n",
      "|03880496| 5308|\n",
      "|03346245| 5100|\n",
      "|03215661| 3571|\n",
      "|02166079| 2997|\n",
      "|03490116| 2578|\n",
      "|01061775| 2410|\n",
      "|01604404| 2006|\n",
      "|01688916| 1667|\n",
      "|03215666| 1644|\n",
      "|03261762| 1628|\n",
      "|03447819| 1603|\n",
      "|01213099| 1569|\n",
      "|03498017| 1494|\n",
      "|03162381| 1454|\n",
      "|01468111| 1294|\n",
      "|02210115| 1227|\n",
      "|03453716| 1170|\n",
      "|01718314| 1151|\n",
      "|01284295| 1103|\n",
      "|01591605| 1098|\n",
      "|03160978| 1070|\n",
      "|03229060| 1067|\n",
      "|03412413| 1058|\n",
      "|04053983| 1042|\n",
      "|03401062|  996|\n",
      "|01452265|  992|\n",
      "|02211082|  903|\n",
      "|03412801|  900|\n",
      "|02022914|  896|\n",
      "|03011902|  880|\n",
      "|03035771|  844|\n",
      "|03481401|  834|\n",
      "|01213019|  830|\n",
      "|01468129|  814|\n",
      "|03269684|  799|\n",
      "|03399897|  798|\n",
      "|03150581|  782|\n",
      "|03035781|  750|\n",
      "|03012814|  742|\n",
      "|UE035329|  742|\n",
      "|03171013|  741|\n",
      "|03153258|  732|\n",
      "|03718105|  729|\n",
      "|02212089|  726|\n",
      "|03057054|  693|\n",
      "|01820222|  672|\n",
      "|01029064|  670|\n",
      "|03412813|  669|\n",
      "|03487931|  668|\n",
      "|03376777|  657|\n",
      "|01783923|  657|\n",
      "|01582552|  655|\n",
      "|02024424|  650|\n",
      "|03074737|  642|\n",
      "|03257481|  640|\n",
      "|01576642|  640|\n",
      "|01779209|  639|\n",
      "|UC045399|  639|\n",
      "|03505085|  621|\n",
      "|HA000065|  605|\n",
      "|03240421|  604|\n",
      "|03087030|  602|\n",
      "|03735346|  588|\n",
      "|03274489|  587|\n",
      "|01735953|  585|\n",
      "|03364499|  579|\n",
      "|03466472|  569|\n",
      "|03057295|  566|\n",
      "|01646274|  553|\n",
      "|03291216|  553|\n",
      "|03087403|  546|\n",
      "|03087427|  543|\n",
      "|03393381|  541|\n",
      "|02231418|  540|\n",
      "|01134483|  540|\n",
      "|01611369|  533|\n",
      "|02018978|  530|\n",
      "|03880077|  526|\n",
      "|02015938|  522|\n",
      "|01782751|  516|\n",
      "|HA000085|  516|\n",
      "|03035793|  515|\n",
      "|03087048|  514|\n",
      "|03035794|  511|\n",
      "|03194145|  509|\n",
      "|03087057|  509|\n",
      "|01689096|  507|\n",
      "|01808828|  507|\n",
      "|01919268|  504|\n",
      "|03389149|  501|\n",
      "|01607100|  489|\n",
      "|03212355|  486|\n",
      "|03642690|  484|\n",
      "|01937725|  480|\n",
      "|03140390|  474|\n",
      "|03347789|  473|\n",
      "|03202370|  469|\n",
      "|03318731|  469|\n",
      "|01404222|  468|\n",
      "|01965801|  467|\n",
      "+--------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/ztrnpf').groupby('RLDGACCT').count().orderBy(desc('count')).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|RLDGACCT|count|\n",
      "+--------+-----+\n",
      "|03880496| 6304|\n",
      "|03346245| 5280|\n",
      "|03215661| 3637|\n",
      "|02166079| 2997|\n",
      "|03490116| 2734|\n",
      "|01061775| 2410|\n",
      "|01604404| 2006|\n",
      "|03261762| 1680|\n",
      "|01688916| 1667|\n",
      "|03215666| 1646|\n",
      "|03498017| 1612|\n",
      "|03447819| 1603|\n",
      "|01213099| 1569|\n",
      "|04053983| 1536|\n",
      "|03162381| 1468|\n",
      "|01468111| 1294|\n",
      "|02210115| 1245|\n",
      "|03453716| 1222|\n",
      "|01718314| 1151|\n",
      "|01284295| 1103|\n",
      "|03229060| 1103|\n",
      "|01591605| 1098|\n",
      "|03160978| 1086|\n",
      "|03412413| 1058|\n",
      "|03401062|  996|\n",
      "|01452265|  992|\n",
      "|03011902|  929|\n",
      "|02211082|  918|\n",
      "|03481401|  901|\n",
      "|03412801|  900|\n",
      "|02022914|  896|\n",
      "|03269684|  871|\n",
      "|03035771|  850|\n",
      "|03399897|  834|\n",
      "|01213019|  830|\n",
      "|01468129|  814|\n",
      "|03150581|  802|\n",
      "|03035781|  784|\n",
      "|UE035329|  742|\n",
      "|03012814|  742|\n",
      "|03171013|  741|\n",
      "|03718105|  739|\n",
      "|03153258|  732|\n",
      "|02212089|  726|\n",
      "|03057054|  693|\n",
      "|03505085|  675|\n",
      "|03376777|  675|\n",
      "|01820222|  672|\n",
      "|03087030|  671|\n",
      "|01029064|  670|\n",
      "|03412813|  669|\n",
      "|03487931|  668|\n",
      "|03257481|  660|\n",
      "|01783923|  657|\n",
      "|01582552|  655|\n",
      "|02024424|  650|\n",
      "|03074737|  642|\n",
      "|01576642|  640|\n",
      "|UC045399|  639|\n",
      "|01779209|  639|\n",
      "|03735346|  628|\n",
      "|HA000065|  608|\n",
      "|03880077|  604|\n",
      "|03240421|  604|\n",
      "|03274489|  603|\n",
      "|01735953|  585|\n",
      "|03364499|  579|\n",
      "|03087403|  570|\n",
      "|03466472|  569|\n",
      "|03291216|  569|\n",
      "|03057295|  566|\n",
      "|03087427|  561|\n",
      "|01646274|  553|\n",
      "|03393381|  547|\n",
      "|03087048|  544|\n",
      "|HA000085|  543|\n",
      "|02231418|  540|\n",
      "|01134483|  540|\n",
      "|01611369|  533|\n",
      "|03035793|  531|\n",
      "|02018978|  530|\n",
      "|03087057|  524|\n",
      "|03035794|  523|\n",
      "|02015938|  522|\n",
      "|01782751|  516|\n",
      "|03194145|  509|\n",
      "|01689096|  507|\n",
      "|01808828|  507|\n",
      "|01919268|  504|\n",
      "|03389149|  501|\n",
      "|03212355|  494|\n",
      "|03202370|  493|\n",
      "|03642690|  492|\n",
      "|01607100|  489|\n",
      "|03634795|  489|\n",
      "|01937725|  480|\n",
      "|03280653|  477|\n",
      "|03347789|  475|\n",
      "|03212361|  474|\n",
      "|03140390|  474|\n",
      "+--------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/adm_ztrnpf').groupby('RLDGACCT').count().orderBy(desc('count')).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+---------+--------+--------+--------+-----+-------+------+---------+---------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+------+--------+-----------+--------------------+--------+\n",
      "|BATCBRN|BATCACTYR|BATCACTMN|BATCTRCDE|RLDGACCT|ORIGCURR|ACCTCURR|CRATE|CNTTYPE|TRANNO|CHDRSTCDA|CHDRSTCDC|TRANDATE| EFFDATE|SACSCODE|SACSTYP06|TRANAMT01|TRANAMT02|TRANAMT03|TRANAMT04|TRANAMT05|TRANAMT06|TRANAMT10|ACCNUM|  CCDATE|EXPIRY_DATE|              datime| RDOCNUM|\n",
      "+-------+---------+---------+---------+--------+--------+--------+-----+-------+------+---------+---------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+------+--------+-----------+--------------------+--------+\n",
      "|     89|     2009|        5|     T928|01916268|      RM|      RM|  1.0|    HID|     2|        L|      AHX|20090525|20090509|      GR|       NP|   953.35|     10.0|      0.0|    143.0|      0.0|   820.35|      0.0| 23184|20090509|   20100508|2009-05-25 16:54:...|00072458|\n",
      "|     89|     2009|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     2|        L|      AHX|20090525|20090509|      GO|       NP|    38.13|      0.0|      0.0|     8.99|     5.72|    23.42|      0.0| 00100|20090509|   20100508|2009-05-25 21:59:...|07401408|\n",
      "|     89|     2008|        5|     T903|01916268|      RM|      RM|  1.0|    HID|     1|        L|      AHX|20080517|20080509|      GR|       NP|    887.8|     10.0|      0.0|   133.17|      0.0|   764.63|      0.0| 23184|20080509|   20090508|2008-05-17 10:38:...|00049858|\n",
      "|     89|     2008|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     1|        L|      AHX|20080520|20080509|      GO|       NP|    35.51|      0.0|      0.0|     8.37|     5.33|    21.81|      0.0| 00100|20080509|   20090508|2008-05-20 21:20:...|07400660|\n",
      "|     89|     2010|        6|     T928|01916268|      RM|      RM|  1.0|    HID|     3|        L|      AHX|20100601|20100509|      GR|       NP|   1023.5|     10.0|      0.0|   153.53|      0.0|   879.97|      0.0| 23184|20100509|   20110508|2010-06-01 14:11:...|00097884|\n",
      "|     89|     2010|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     3|        L|      AHX|20100601|20100509|      GO|       NP|    40.94|      0.0|      0.0|      0.0|     6.14|     34.8|      0.0| 00100|20100509|   20110508|2010-06-01 21:18:...|07402739|\n",
      "|     89|     2010|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     3|        L|      AHX|20100601|20100509|      GO|       NP|   491.28|      0.0|      0.0|      0.0|    73.69|   417.59|      0.0| 24221|20100509|   20110508|2010-06-01 21:18:...|07402745|\n",
      "|     89|     2012|        5|     T928|01916268|      RM|      RM|  1.0|    HID|     5|        L|      AHX|20120525|20120509|      GR|       NP|  1314.45|     10.0|      0.0|   197.17|      0.0|  1127.28|      0.0| 23184|20120509|   20130508|2012-05-25 15:55:...|00167298|\n",
      "|     89|     2012|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     5|        L|      AHX|20120525|20120509|      GO|       NP|    32.85|      0.0|      0.0|      0.0|     4.93|    27.92|      0.0| 00100|20120509|   20130508|2012-05-25 21:17:...|07406486|\n",
      "|     89|     2012|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     5|        L|      AHX|20120525|20120509|      GO|       NP|   640.79|      0.0|      0.0|      0.0|    96.12|   544.67|      0.0| 24221|20120509|   20130508|2012-05-25 21:17:...|07406491|\n",
      "|     89|     2011|        6|     T928|01916268|      RM|      RM|  1.0|    HID|     4|        L|      AHX|20110602|20110509|      GR|       NP|  1089.05|     10.0|      0.0|   163.36|      0.0|   935.69|      0.0| 23184|20110509|   20120508|2011-06-02 17:28:...|00128540|\n",
      "|     89|     2011|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     4|        L|      AHX|20110602|20110509|      GO|       NP|    27.22|      0.0|      0.0|      0.0|     4.08|    23.14|      0.0| 00100|20110509|   20120508|2011-06-02 21:11:...|07404461|\n",
      "|     89|     2011|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     4|        L|      AHX|20110602|20110509|      GO|       NP|    530.9|      0.0|      0.0|      0.0|    79.64|   451.26|      0.0| 24221|20110509|   20120508|2011-06-02 21:11:...|07404470|\n",
      "|     89|     2013|        6|     T928|01916268|      RM|      RM|  1.0|    HID|     6|        L|      AHX|20130604|20130509|      GR|       NP|  1555.95|     10.0|      0.0|   233.39|      0.0|  1332.56|      0.0| 23184|20130509|   20140508|2013-06-04 17:12:...|00205119|\n",
      "|     89|     2013|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     6|        L|      AHX|20130604|20130509|      GO|       NP|    38.88|      0.0|      0.0|      0.0|     5.83|    33.05|      0.0| 00100|20130509|   20140508|2013-06-04 21:32:...|07408603|\n",
      "|     89|     2013|        6|     BR9A|01916268|      RM|      RM|  1.0|    HID|     6|        L|      AHX|20130604|20130509|      GO|       NP|   758.51|      0.0|      0.0|      0.0|   113.77|   644.74|      0.0| 24221|20130509|   20140508|2013-06-04 21:32:...|07408615|\n",
      "|     89|     2014|        5|     T928|01916268|      RM|      RM|  1.0|    HID|     7|        L|      AHX|20140514|20140509|      GR|       NP|  1645.65|     10.0|      0.0|   246.85|      0.0|   1408.8|      0.0| 23184|20140509|   20150508|2014-05-14 15:46:...|00281048|\n",
      "|     89|     2014|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     7|        L|      AHX|20140514|20140509|      GO|       NP|    41.13|      0.0|      0.0|      0.0|     6.18|    34.95|      0.0| 00100|20140509|   20150508|2014-05-14 21:40:...|07410575|\n",
      "|     89|     2015|        5|     T928|01916268|      RM|      RM|  1.0|    HID|     8|        L|      AHX|20150512|20150509|      GR|       NP|   2295.4|     10.0|      0.0|   344.31|      0.0|  2098.82|      0.0| 23184|20150509|   20160508|2015-05-12 11:05:...|00367781|\n",
      "|     89|     2015|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|     8|        L|      AHX|20150512|20150509|      GO|       NP|    57.36|      0.0|      0.0|      0.0|     8.61|    51.67|      0.0| 00100|20150509|   20160508|2015-05-12 21:46:...|07412052|\n",
      "|     89|     2017|        5|     T928|01916268|      RM|      RM|  1.0|    HID|    11|        L|      AHX|20170517|20170509|      GR|       NP|   2582.9|     10.0|      0.0|   387.44|      0.0|  2360.44|      0.0| 23184|20170509|   20180508|2017-05-17 10:38:...|00604159|\n",
      "|     89|     2017|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|    11|        L|      AHX|20170517|20170509|      GO|       NP|    64.56|      0.0|      0.0|      0.0|     9.69|    58.16|      0.0| 00100|20170509|   20180508|2017-05-17 21:18:...|07416021|\n",
      "|     89|     2016|        5|     T928|01916268|      RM|      RM|  1.0|    HID|    10|        L|      AHX|20160512|20160509|      GR|       NP|   2431.1|     10.0|      0.0|   364.67|      0.0|   2222.3|      0.0| 23184|20160509|   20170508|2016-05-12 17:25:...|00536670|\n",
      "|     89|     2016|        5|     BR9A|01916268|      RM|      RM|  1.0|    HID|    10|        L|      AHX|20160512|20160509|      GO|       NP|    60.76|      0.0|      0.0|      0.0|     9.11|    54.75|      0.0| 00100|20160509|   20170508|2016-05-12 21:35:...|07414515|\n",
      "|     89|     2015|        7|     T933|01916268|      RM|      RM|  1.0|    HID|     9|        L|      AHX|20150705|20150509|      GR|       NP|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0| 23184|20150509|   20160508|2015-07-05 11:29:...|00438670|\n",
      "|     89|     2015|        7|     BR9A|01916268|      RM|      RM|  1.0|    HID|     9|        L|      AHX|20150705|20150509|      GO|       NP|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0| 00100|20150509|   20160508|2015-07-05 13:16:...|07412483|\n",
      "+-------+---------+---------+---------+--------+--------+--------+-----+-------+------+---------+---------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+------+--------+-----------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/adm_ztrnpf').filter(col('RLDGACCT')=='01916268').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+--------+--------+-----+-------+------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------+--------+--------------+--------------+--------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+------+------+--------+-----------+----+--------+-----+------+------------+----------+--------------------+------+--------+-------+-------+-------+------+--------+---------+------+------+-------+-------+--------+--------+\n",
      "|BATCPFX|BATCCOY|BATCBRN|BATCACTYR|BATCACTMN|BATCTRCDE|BATCBATCH|RLDGPFX|RLDGCOY|RLDGACCT|ORIGCURR|ACCTCURR|CRATE|CNTTYPE|TRANNO|CNTBRANCH|CHDRSTCDA|CHDRSTCDB|CHDRSTCDC|CHDRSTCDD|CHDRSTCDE|POSTMONTH|POSTYEAR|TRANDATE|TRANTIME| EFFDATE|SACSCODE|SACSTYP01|SACSTYP02|SACSTYP03|SACSTYP04|SACSTYP05|SACSTYP06|SACSTYP07|SACSTYP08|SACSTYP09|SACSTYP10|SACSTYP11|SACSTYP12|SACSTYP13|SACSTYP14|SACSTYP15|SACSTYP16|SACSTYP17|SACSTYP18|SACSTYP19|SACSTYP20|SACSTYP21|SACSTYP22|SACSTYP23|SACSTYP24|SACSTYP25|SACSTYP26|TRANAMT01|TRANAMT02|TRANAMT03|TRANAMT04|TRANAMT05|TRANAMT06|TRANAMT07|TRANAMT08|TRANAMT09|TRANAMT10|TRANAMT11|TRANAMT12|TRANAMT13|TRANAMT14|TRANAMT15|TRANAMT16|TRANAMT17|TRANAMT18|TRANAMT19|TRANAMT20|TRANAMT21|TRANAMT22|TRANAMT23|TRANAMT24|TRANAMT25|TRANAMT26|GLSIGN01|GLSIGN02|GLSIGN03|GLSIGN04|GLSIGN05|GLSIGN06|GLSIGN07|GLSIGN08|GLSIGN09|GLSIGN10|GLSIGN11|GLSIGN12|GLSIGN13|GLSIGN14|GLSIGN15|GLSIGN16|GLSIGN17|GLSIGN18|GLSIGN19|GLSIGN20|GLSIGN21|GLSIGN22|GLSIGN23|GLSIGN24|GLSIGN25|GLSIGN26|GENLCUR|GENLPFX|GENLCOY|      GLCODE01|      GLCODE02|      GLCODE03|      GLCODE04|      GLCODE05|      GLCODE06|      GLCODE07|      GLCODE08|      GLCODE09|      GLCODE10|GLCODE11|GLCODE12|      GLCODE13|      GLCODE14|      GLCODE15|GLCODE16|GLCODE17|GLCODE18|GLCODE19|GLCODE20|GLCODE21|GLCODE22|GLCODE23|GLCODE24|GLCODE25|GLCODE26|ACCPFX|ACCCOY|ACCNUM|  CCDATE|EXPIRY_DATE|LIFE|COVERAGE|RIDER|ACCTYP|USER_PROFILE|  JOB_NAME|              datime|ORAGNT|BANKCODE|DOCTPFX|DOCTCOY|DOCTNUM|INSTNO|BILLFREQ|STATREASN|PRTFLG|RITYPE|RDOCPFX|RDOCCOY| RDOCNUM|NOSCHCPY|\n",
      "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+--------+--------+-----+-------+------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------+--------+--------------+--------------+--------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+------+------+--------+-----------+----+--------+-----+------+------------+----------+--------------------+------+--------+-------+-------+-------+------+--------+---------+------+------+-------+-------+--------+--------+\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     8|       19|        L|      AGY|      001|      MAL|         |       03|    2008|20080303|  150110|20080225|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 15:01:...|      |        |       |       |       |     0|      00|       VF|    OL|      |     CA|      1|        |       1|\n",
      "|     BA|      1|     19|     2010|       10|     B421|    00031|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|    11|       19|        L|      AGY|      001|      MAL|         |       10|    2010|20101023|   65548|20110103|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |    405.7|     10.0|      0.0|    40.58|      0.0|   375.12|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20110103|   20120102|    |        |     |      |     MAXAOPR|P1RENEWALS|2010-10-23 06:55:...|      |        |       |       |       |     0|      01|         |      |      |       |       |        |       1|\n",
      "|     BA|      1|     19|     2010|        1|     T413|    00048|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|    10|       19|        L|      AGY|      001|      MAL|         |       01|    2010|20100107|  150835|20100103|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |    306.1|     10.0|      0.0|    30.61|      0.0|   285.49|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20100103|   20110102|    |        |     |      |    MAXUUNP2|QPADEV005F|2010-01-07 15:08:...|      |      63|       |       |       |     0|      00|         |      |      |     CA|      1|R1061018|       1|\n",
      "|     BA|      1|     19|     2010|        1|     T413|    00048|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|    10|       19|        L|      SRE|      001|         |         |       01|    2010|20100107|  150835|20100103|      RP|        P|       R1|        D|       C1|       C2|       NP|       R2|       R3|       R4|       AF|       C3|       C4|       R5|       R6|       R7|         |         |         |         |         |         |         |         |         |         |         |    12.25|      0.0|      0.0|     0.83|     1.22|     10.2|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       +|       +|       -|       -|       -|       -|       +|       +|       +|       -|       -|       -|       +|       +|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00RWP-001-SRE|L1973134000000|L00RWP-001-SRE|L00RWC-001-SRE|L00RWC-001-SRE|L0015110000000|L1973136000000|       NOTUSED|       NOTUSED|       NOTUSED| NOTUSED| NOTUSED|       NOTUSED|       NOTUSED|       NOTUSED|        |        |        |        |        |        |        |        |        |        |        |    RI|     1|MR05MV|20100103|   20110102|    |        |     |      |    MAXUUNP2|QPADEV005F|2010-01-07 15:08:...|      |        |       |       |       |     0|      00|         |      |     G|       |       |        |       1|\n",
      "|     BA|      1|     19|     2009|        1|     T413|    00041|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     9|       19|        L|      AGY|      001|      MAL|         |       01|    2009|20081231|  120138|20090103|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |    354.9|     10.0|      0.0|    35.49|      0.0|   329.41|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20090103|   20100102|    |        |     |      |    MAXUUPO2|QPADEV005V|2008-12-31 12:01:...|      |      63|       |       |       |     0|      00|         |      |      |     CA|      1|R0859000|       1|\n",
      "|     BA|      1|     19|     2009|        1|     T413|    00041|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     9|       19|        L|      SRE|      001|         |         |       01|    2009|20081231|  120138|20090103|      RP|        P|       R1|        D|       C1|       C2|       NP|       R2|       R3|       R4|       AF|       C3|       C4|       R5|       R6|       R7|         |         |         |         |         |         |         |         |         |         |         |     14.2|      0.0|      0.0|     0.96|     1.42|    11.82|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       +|       +|       -|       -|       -|       -|       +|       +|       +|       -|       -|       -|       +|       +|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00RWP-001-SRE|L1973134000000|L00RWP-001-SRE|L00RWC-001-SRE|L00RWC-001-SRE|L0015110000000|L1973136000000|       NOTUSED|       NOTUSED|       NOTUSED| NOTUSED| NOTUSED|       NOTUSED|       NOTUSED|       NOTUSED|        |        |        |        |        |        |        |        |        |        |        |    RI|     1|MR05MV|20090103|   20100102|    |        |     |      |    MAXUUPO2|QPADEV005V|2008-12-31 12:01:...|      |        |       |       |       |     0|      00|         |      |     G|       |       |        |       1|\n",
      "|     BA|      1|     19|     2008|        1|     T405|    00041|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     1|       19|        L|      AGY|      001|      MAL|         |       01|    2008|20080115|  140028|20080103|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |   281.46|     10.0|      0.0|    28.14|      0.0|   263.32|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |    MAXUUSF2|QPADEV0038|2008-01-15 14:00:...|      |      63|       |       |       |     0|      00|         |    OL|      |     CA|      1|R0668782|       1|\n",
      "|     BA|      1|     19|     2008|        1|     T405|    00041|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     1|       19|        L|      SRE|      001|         |         |       01|    2008|20080115|  140028|20080103|      RP|        P|       R1|        D|       C1|       C2|       NP|       R2|       R3|       R4|       AF|       C3|       C4|       R5|       R6|       R7|         |         |         |         |         |         |         |         |         |         |         |    11.26|      0.0|      0.0|     0.76|     1.12|     9.38|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       +|       +|       -|       -|       -|       -|       +|       +|       +|       -|       -|       -|       +|       +|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00RWP-001-SRE|L1973134000000|L00RWP-001-SRE|L00RWC-001-SRE|L00RWC-001-SRE|L0015110000000|L1973136000000|       NOTUSED|       NOTUSED|       NOTUSED| NOTUSED| NOTUSED|       NOTUSED|       NOTUSED|       NOTUSED|        |        |        |        |        |        |        |        |        |        |        |    RI|     1|MR05MV|20080103|   20090102|    |        |     |      |    MAXUUSF2|QPADEV0038|2008-01-15 14:00:...|      |        |       |       |       |     0|      00|         |      |     G|       |       |        |       1|\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     2|       19|        L|      AGY|      001|      MAL|         |       03|    2008|20080303|  145434|20080225|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |    149.6|      0.0|      0.0|    14.96|      0.0|   134.64|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 14:54:...|      |      18|       |       |       |     0|      00|       VC|    OL|      |     CA|      1|R0691248|       1|\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     2|       19|        L|      SRE|      001|         |         |       03|    2008|20080303|  145434|20080225|      RP|        P|       R1|        D|       C1|       C2|       NP|       R2|       R3|       R4|       AF|       C3|       C4|       R5|       R6|       R7|         |         |         |         |         |         |         |         |         |         |         |     5.99|      0.0|      0.0|      0.4|      0.6|     4.99|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       +|       +|       -|       -|       -|       -|       +|       +|       +|       -|       -|       -|       +|       +|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00RWP-001-SRE|L1973134000000|L00RWP-001-SRE|L00RWC-001-SRE|L00RWC-001-SRE|L0015110000000|L1973136000000|       NOTUSED|       NOTUSED|       NOTUSED| NOTUSED| NOTUSED|       NOTUSED|       NOTUSED|       NOTUSED|        |        |        |        |        |        |        |        |        |        |        |    RI|     1|MR05MV|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 14:54:...|      |        |       |       |       |     0|      00|       VC|      |     G|       |       |        |       0|\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     4|       19|        L|      AGY|      001|      MAL|         |       03|    2008|20080303|  145722|20080225|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |      0.0|      0.0|      0.0|      0.0|      0.0|     10.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|     10.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 14:57:...|      |      18|       |       |       |     0|      00|       VL|    OL|      |     CA|      1|R0691248|       1|\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     5|       19|        L|      AGY|      001|      MAL|         |       03|    2008|20080303|  145836|20080225|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 14:58:...|      |        |       |       |       |     0|      00|       VF|    OL|      |     CA|      1|        |       1|\n",
      "|     BA|      1|     19|     2008|        3|     T409|    00002|     CH|      1|01865273|      RM|      RM|  1.0|    VPP|     7|       19|        L|      AGY|      001|      MAL|         |       03|    2008|20080303|  150007|20080225|      FG|        P|       EC|        D|       C1|       C2|       NP|       E1|       E2|       E3|       AF|       C3|       C4|       E4|       E5|       E6|         |         |         |         |         |         |         |         |         |         |         |      0.0|      0.0|      0.0|      0.0|      0.0|     10.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|     10.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|       -|       -|       +|       +|       +|       +|       -|       -|       -|       +|       +|       +|       -|       -|       +|        |        |        |        |        |        |        |        |        |        |        |     RM|     GE|      1|L00GWP-001-AGY|L0024309000000|L00GWP-001-AGY|L00GWC-001-AGY|L00GWC-001-AGY|L0015110000000|L0024310000000|L00GWP-001-AGY|L1973136000000|L00GWC-001-AGY| NOTUSED| NOTUSED|L00GWP-001-AGY|L00GWP-001-AGY|L0015389000000|        |        |        |        |        |        |        |        |        |        |        |    AG|     1| 05055|20080103|   20090102|    |        |     |      |     MAXSSSL|QPADEV0114|2008-03-03 15:00:...|      |      18|       |       |       |     0|      00|       VL|    OL|      |     CA|      1|R0691250|       1|\n",
      "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+--------+--------+-----+-------+------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------+--------+--------------+--------------+--------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+------+------+--------+-----------+----+--------+-----+------+------------+----------+--------------------+------+--------+-------+-------+-------+------+--------+---------+------+------+-------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('/group/axa_malaysia/data/ztrnpf').filter(col('RLDGACCT')=='01865273').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df4.withColumn('tranno',col('tranno').cast('string'))\n",
    "df4.write.saveAsTable('axa_malaysia.pr_gr_psea14', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o244.saveAsTable.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:147)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:101)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeAndRead(DataSource.scala:500)\n\tat org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run(createDataSourceTables.scala:263)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:404)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:358)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3, localhost, executor driver): java.io.FileNotFoundException: /tmp/blockmgr-0aeb9ab9-deff-4a6d-a636-f03ebfdfca33/3b/temp_shuffle_81b023bb-1741-4f9c-8d05-2cd4de7f5f57 (Too many open files)\n\tat java.io.FileOutputStream.open(Native Method)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:221)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:127)\n\t... 43 more\nCaused by: java.io.FileNotFoundException: /tmp/blockmgr-0aeb9ab9-deff-4a6d-a636-f03ebfdfca33/3b/temp_shuffle_81b023bb-1741-4f9c-8d05-2cd4de7f5f57 (Too many open files)\n\tat java.io.FileOutputStream.open(Native Method)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:221)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b15d65fc6c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axa_malaysia.pr_gr_psea14'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msaveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o244.saveAsTable.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:147)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:101)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeAndRead(DataSource.scala:500)\n\tat org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run(createDataSourceTables.scala:263)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:404)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:358)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 1.0 failed 1 times, most recent failure: Lost task 2.0 in stage 1.0 (TID 3, localhost, executor driver): java.io.FileNotFoundException: /tmp/blockmgr-0aeb9ab9-deff-4a6d-a636-f03ebfdfca33/3b/temp_shuffle_81b023bb-1741-4f9c-8d05-2cd4de7f5f57 (Too many open files)\n\tat java.io.FileOutputStream.open(Native Method)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:221)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:127)\n\t... 43 more\nCaused by: java.io.FileNotFoundException: /tmp/blockmgr-0aeb9ab9-deff-4a6d-a636-f03ebfdfca33/3b/temp_shuffle_81b023bb-1741-4f9c-8d05-2cd4de7f5f57 (Too many open files)\n\tat java.io.FileOutputStream.open(Native Method)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:221)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:102)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:115)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:235)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:152)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "| chdrnum|tranno|fg_premium_total|fg_commission_total|co_premium_total|co_commission_total|rp_premium_total|rp_commission_total|\n",
      "+--------+------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "|04226526|     1|          218.53|              32.78|          174.82|              29.94|           15.04|               2.98|\n",
      "|01383769|     1|          859.96|             128.99|          515.97|              83.97|          159.63|              27.98|\n",
      "|01349326|     1|          482.54|              72.38|          289.53|              47.13|           89.57|              15.71|\n",
      "|01278446|     1|          260.78|              39.12|          156.47|              25.48|           24.78|               4.50|\n",
      "|03345571|     1|         3136.07|               0.00|          553.42|             106.54|         2330.26|             476.02|\n",
      "|UZ030808|    34|            0.00|               0.00|         3000.00|             577.50|            0.00|               0.00|\n",
      "|01535222|     1|          138.10|              20.72|           27.62|               4.49|            5.52|               1.06|\n",
      "|02236980|     3|          193.26|               0.00|          113.68|              19.47|            5.68|               1.57|\n",
      "|03049007|     9|         1357.04|             203.56|          474.95|              81.38|          224.49|              61.85|\n",
      "|02022914|     5|         3376.54|             506.48|          675.31|             115.62|         2614.51|             605.04|\n",
      "|02099494|     8|         1360.32|             204.05|          272.06|              46.59|          742.49|             145.01|\n",
      "|04080693|     1|       679906.19|          101985.98|       203971.90|           34930.46|       237967.36|           76774.27|\n",
      "|01114942|     1|          182.79|              20.09|           95.70|              16.40|            4.78|               1.33|\n",
      "|03213470|     3|            0.00|               0.00|         1013.55|             195.13|           -7.14|              -1.38|\n",
      "|01409783|     2|          199.17|              29.88|           79.66|              13.66|           87.24|              17.31|\n",
      "|03994059|     1|           29.04|               4.36|           23.95|               4.10|            2.29|               0.45|\n",
      "|03520046|     3|          143.51|               0.00|           67.56|              11.53|           50.66|              16.21|\n",
      "|01408136|     1|          107.08|              16.06|           64.24|              10.44|           19.87|               3.48|\n",
      "|01307063|     1|           51.52|               7.73|           30.91|               5.03|            4.90|               0.88|\n",
      "|02244073|     1|        45132.26|               0.00|         7964.52|            1533.17|        33535.53|            6850.53|\n",
      "+--------+------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.filter(col('co_premium_total')>0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.read.parquet('/user/cchin/data/sas_403/transv_cl_quali_psea.parquet').write.saveAsTable('axa_malaysia.cl_quali_psea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[chdrnum: string, tranno: int, agentid: string, batctrcde: string, chdrstcdc: string, batcbrn: int, yrm: int, d_tran: date, d_eff: date, d_com: date, d_exp: date, trantype: string, rskno: int, premcl: string, gwp: double, gwc: double, cwp: double, cwc: double]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transv_pr_gr_psea.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transv_pr_gr_psea.write.saveAsTable('axa_malaysia.pr_gr_psea2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yrm_gwp_spark = transv_pr_gr_psea.groupby('yrm').sum('gwp').orderBy('yrm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "|chdrnum|tranno|agentid|batctrcde|chdrstcdc|batcbrn|yrm|d_tran|d_eff|d_com|d_exp|trantype|rskno|premcl|gwp|gwc|cwp|cwc|\n",
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "+-------+------+-------+---------+---------+-------+---+------+-----+-----+-----+--------+-----+------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transv_pr_gr_psea.filter(col('chdrnum')=='01141394').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[yrm: int, sum(gwp): double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrm_gwp_spark.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrm_gwp_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|   yrm|            sum(gwp)|\n",
      "+------+--------------------+\n",
      "|199902| -21835.879999999997|\n",
      "|200207|1.6928779479999997E7|\n",
      "|200208|2.2709575599999998E7|\n",
      "|200209|2.5989185189999994E7|\n",
      "|200210|1.9407926239999995E7|\n",
      "|200211|       1.868669075E7|\n",
      "|200212|2.4717630510000017E7|\n",
      "|200301|1.6372270670000004E7|\n",
      "|200302|3.1312582300000023E7|\n",
      "|200303|       2.896180276E7|\n",
      "|200304|       2.221948814E7|\n",
      "|200305| 4.518518199529997E9|\n",
      "|200306|2.1683238929999992E7|\n",
      "|200307|        2.26903872E7|\n",
      "|200308|1.8556353750000007E7|\n",
      "|200309| 4.150809044999998E7|\n",
      "|200310|1.8535794570000004E7|\n",
      "|200311|1.7626995979999986E7|\n",
      "|200312| 5.996708582999999E7|\n",
      "|200401|1.9746300109999996E7|\n",
      "|200402|3.2714467529999994E7|\n",
      "|200403|       2.471955417E7|\n",
      "|200404| 3.790156750000002E7|\n",
      "|200405|1.7267052630000003E7|\n",
      "|200406|       2.522090485E7|\n",
      "|200407|2.1681164340000004E7|\n",
      "|200408| 2.038332896999999E7|\n",
      "|200409| 2.408401493999999E7|\n",
      "|200410|2.3071639579999987E7|\n",
      "|200411|       2.529502642E7|\n",
      "|200412|4.3641959779999964E7|\n",
      "|200501|2.5256093310000006E7|\n",
      "|200502|2.7189948470000017E7|\n",
      "|200503|3.2846751900000006E7|\n",
      "|200504|2.6784995099999994E7|\n",
      "|200505|2.5990845630000006E7|\n",
      "|200506|3.5032969259999976E7|\n",
      "|200507| 3.201504375000001E7|\n",
      "|200508| 2.215723771000001E7|\n",
      "|200509| 2.737653994000001E7|\n",
      "|200510|2.2465936429999996E7|\n",
      "|200511|2.9831966070000015E7|\n",
      "|200512|       2.444260389E7|\n",
      "|200601|3.2954980270000003E7|\n",
      "|200602|3.1441461000000004E7|\n",
      "|200603|3.5540346360000014E7|\n",
      "|200604|2.8121704140000004E7|\n",
      "|200605|       2.342307569E7|\n",
      "|200606| 3.599020060000001E7|\n",
      "|200607| 3.088091883000001E7|\n",
      "|200608|2.6093422100000005E7|\n",
      "|200609|2.2741338199999988E7|\n",
      "|200610| 2.625445737999999E7|\n",
      "|200611| 2.420539533000002E7|\n",
      "|200612| 4.004708325999999E7|\n",
      "|200701|       3.792476331E7|\n",
      "|200702|2.6312906209999986E7|\n",
      "|200703| 4.491594778999998E7|\n",
      "|200704|3.3913559779999994E7|\n",
      "|200705|2.4688355449999973E7|\n",
      "|200706|2.2933760060000014E7|\n",
      "|200707| 3.721884668000001E7|\n",
      "|200708|       2.544892963E7|\n",
      "|200709| 2.537048363000001E7|\n",
      "|200710|       2.458556239E7|\n",
      "|200711|2.4943978189999975E7|\n",
      "|200712|2.9743485829999983E7|\n",
      "|200801| 4.805985698000002E7|\n",
      "|200802|3.0271937080000013E7|\n",
      "|200803|       3.600372929E7|\n",
      "|200804| 3.368566810000001E7|\n",
      "|200805|2.7846546859999996E7|\n",
      "|200806|2.5778916519999996E7|\n",
      "|200807|         4.5948724E7|\n",
      "|200808|3.4446809660000004E7|\n",
      "|200809|2.7407313139999986E7|\n",
      "|200810|       2.996548848E7|\n",
      "|200811|3.1112165069999997E7|\n",
      "|200812|       3.499078273E7|\n",
      "|200901|3.7670040820000015E7|\n",
      "|200902|       4.010690617E7|\n",
      "|200903|       5.117874994E7|\n",
      "|200904| 3.484207124999999E7|\n",
      "|200905|        3.27580161E7|\n",
      "|200906|        4.17892647E7|\n",
      "|200907| 4.249859406000001E7|\n",
      "|200908|3.2031831959999982E7|\n",
      "|200909|2.2879289853999996E8|\n",
      "|200910|2.9541869080000006E7|\n",
      "|200911|4.2028718749999985E7|\n",
      "|200912|5.4740892030000016E7|\n",
      "|201001|       4.242674752E7|\n",
      "|201002| 5.178233170999998E7|\n",
      "|201003| 5.737683512000001E7|\n",
      "|201004| 3.781783351000001E7|\n",
      "|201005| 3.877614838000003E7|\n",
      "|201006| 4.196235181000003E7|\n",
      "|201007| 6.197745586000001E7|\n",
      "|201008| 4.317241873000004E7|\n",
      "|201009| 5.026642354000002E7|\n",
      "|201010|4.6509253950000025E7|\n",
      "|201011| 4.251481491000002E7|\n",
      "|201012|       4.689876936E7|\n",
      "|201101|5.8872191449999996E7|\n",
      "|201102|1.1087616111000004E8|\n",
      "|201103|1.0296256761999995E8|\n",
      "|201104|  6.82104974900001E7|\n",
      "|201105| 7.728142488000007E7|\n",
      "|201106| 7.146949815000026E7|\n",
      "|201107| 7.224104089000009E7|\n",
      "|201108|  8.26681252100001E7|\n",
      "|201109| 8.075566865000008E7|\n",
      "|201110| 8.218110415000011E7|\n",
      "|201111| 8.575436377000004E7|\n",
      "|201112| 7.470942263000014E7|\n",
      "|201201|1.0658621758000004E8|\n",
      "|201202| 9.032892544999999E7|\n",
      "|201203|  8.94039961000001E7|\n",
      "|201204| 9.220799167000005E7|\n",
      "|201205| 8.139926688000008E7|\n",
      "|201206| 6.722476155000007E7|\n",
      "|201207|1.1598471653000015E8|\n",
      "|201208| 8.600120631000012E7|\n",
      "|201209| 8.495159235000008E7|\n",
      "|201210|  9.57839189900001E7|\n",
      "|201211| 9.517255364000005E7|\n",
      "|201212| 9.765043793000011E7|\n",
      "|201301|1.2398671635999995E8|\n",
      "|201302| 9.937473639000016E7|\n",
      "|201303|1.1566283885000011E8|\n",
      "|201304|1.0379192680000018E8|\n",
      "|201305| 8.900939206000012E7|\n",
      "|201306| 8.132236938000011E7|\n",
      "|201307|1.2984620491000009E8|\n",
      "|201308| 9.320058472000016E7|\n",
      "|201309|1.0595653260000016E8|\n",
      "|201310|1.1838390971000019E8|\n",
      "|201311| 9.212219610000013E7|\n",
      "|201312| 9.347626303000015E7|\n",
      "|201401|1.2469389513000011E8|\n",
      "|201402|1.1499551109000011E8|\n",
      "|201403|1.3338111009000003E8|\n",
      "|201404|1.2412085093000004E8|\n",
      "|201405|1.0548380864000005E8|\n",
      "|201406| 9.967041510000041E7|\n",
      "|201407| 1.540681898000002E8|\n",
      "|201408|1.5421097116000038E8|\n",
      "|201409|1.2836988452000043E8|\n",
      "|201410|1.3494480968000028E8|\n",
      "|201411|1.2122756466000022E8|\n",
      "|201412| 7.319270375000018E7|\n",
      "|201501| 1.913432020899998E8|\n",
      "|201502|1.3864745452000022E8|\n",
      "|201503| 1.049876094300002E8|\n",
      "|201504|1.6438237354000005E8|\n",
      "|201505|1.2093959138000046E8|\n",
      "|201506| 8.676439286000031E7|\n",
      "|201507|1.3148561487000018E8|\n",
      "|201508|2.7279893932000107E8|\n",
      "|201509|1.3706444652000022E8|\n",
      "|201510| 1.667581134000005E8|\n",
      "|201511|1.3668203803000018E8|\n",
      "|201512| 8.891428593000005E7|\n",
      "|201601|2.2858802376999944E8|\n",
      "|201602|1.5555087487000006E8|\n",
      "|201603|1.4562973337999985E8|\n",
      "|201604|1.9370368409624997E8|\n",
      "|201605|1.6283402168999964E8|\n",
      "|201606|1.5743216832999986E8|\n",
      "|201607|1.7086020739999998E8|\n",
      "|201608|1.7205039633000052E8|\n",
      "|201609|1.8610670974000028E8|\n",
      "|201610|1.9611610140000042E8|\n",
      "|201611| 1.494408442000001E8|\n",
      "|201612|1.3612130945000014E8|\n",
      "|201701|2.3318227206999874E8|\n",
      "|201702|1.2950869660999964E8|\n",
      "|201703|1.6350468456999972E8|\n",
      "|201704|1.9366092266999987E8|\n",
      "|201705| 1.944339188799999E8|\n",
      "|201706|  9.60272784800001E7|\n",
      "|201707|1.3615247645999986E8|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yrm_gwp_spark.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yrm_gwp_spark.coalesce(1).write.csv('yrm_gwp_spark.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: hdfs://bigplay-asia-nameservice/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04;'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o43.parquet.\n: org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://bigplay-asia-nameservice/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04;\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:441)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f7215ab2acd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mztrnpf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m spark.read.parquet(ztrnpf_path)[['batcactyr',\n\u001b[0m\u001b[0;32m      3\u001b[0m  \u001b[1;34m'batcactmn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m  \u001b[1;34m'rldgacct'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m  \u001b[1;34m'tranno'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[1;34m(self, *paths)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: 'Path does not exist: hdfs://bigplay-asia-nameservice/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04;'"
     ]
    }
   ],
   "source": [
    "ztrnpf_path = '/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2017/mm=11/dd=04'\n",
    "spark.read.parquet(ztrnpf_path)[['batcactyr',\n",
    " 'batcactmn',\n",
    " 'rldgacct',\n",
    " 'tranno',\n",
    " 'ccdate',\n",
    " 'effdate',\n",
    " 'accnum',\n",
    " 'expiry_date',\n",
    " 'batctrcde',\n",
    " 'sacscode',\n",
    " 'trandate',\n",
    " 'chdrstcdc',\n",
    " 'tranamt01',\n",
    " 'tranamt02',\n",
    " 'tranamt03',\n",
    " 'tranamt04',\n",
    " 'tranamt05',\n",
    " 'tranamt14',\n",
    " 'batcbrn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 2.0.0 - YARN [anaconda3-4.1.1]",
   "language": "",
   "name": "pyspark2_yarn_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
