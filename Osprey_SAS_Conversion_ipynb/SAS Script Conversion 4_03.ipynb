{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "#cmovpf_path = '/group/axa_malaysia/data/adm_cmovpf'\n",
    "#ctrnpf_path = '/group/axa_malaysia/data/adm_ctrnpf'\n",
    "#ltrnpf_path = '/group/axa_malaysia/data/adm_ltrnpf'\n",
    "#clampf_path = '/group/axa_malaysia/data/adm_clampf'\n",
    "#clxdpf_path = '/group/axa_malaysia/data/adm_clxdpf'\n",
    "#transv_cl_quanti_psea_path = 'data/sas_403/transv_cl_quanti_psea.parquet'\n",
    "#adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "\n",
    "#cal_yr = datetime.now().year\n",
    "#cal_mth = datetime.now().month\n",
    "#cal_day = datetime.now().day\n",
    "#cal_yrm = cal_yr*100 + cal_mth\n",
    "#cal_ymd = cal_yrm*100 + cal_day\n",
    "\n",
    "def convert_dateb(x):\n",
    "    x_str = str(x).strip()\n",
    "    if len(x_str) == 6 and int(x_str[0]) > 7:\n",
    "        return 19000000 + x\n",
    "    else: \n",
    "        return 20000000 + x\n",
    "_convert_dateb_udf = udf(convert_dateb, IntegerType())\n",
    "\n",
    "errdate = to_date(lit('2999-12-31'))\n",
    "def format_date(strdate):\n",
    "    try: \n",
    "        return datetime.strptime(str(strdate),'%Y%m%d').strftime('%Y-%m-%d')\n",
    "    except: \n",
    "        return '2999-12-31'\n",
    "_format_date = udf(format_date,StringType())\n",
    "    \n",
    "def claims_quanti_psea(cmovpf_path,ctrnpf_path,ltrnpf_path, output_folder = 'data/sas_403/'):    \n",
    "    cmovpf = spark.read.parquet(cmovpf_path)\n",
    "    ctrnpf = spark.read.parquet(ctrnpf_path)\n",
    "    ltrnpf = spark.read.parquet(ltrnpf_path)\n",
    "\n",
    "    #*----------------------------------------------------------*/\n",
    "    #*                          PART I                          */\n",
    "    #*----------------------------------------------------------*/\n",
    "\n",
    "\n",
    "    cmovpf = cmovpf[['clmpfx','clmcoy','claim','tranno','batcactyr','batcactmn',\n",
    "            'transaction_date','validflag','chgbal','paymnt','chgbal_ri','paymnt_ri',\n",
    "            'clstat','paycde','clrate','reqnno','receipt','batctrcde']]\\\n",
    "    .filter((col('clmpfx')=='CL') & (col('clmcoy')==1) & (col('validflag')==1))\n",
    "\n",
    "    cmovpf = cmovpf.withColumn(\"d_tran\", to_date(_format_date(_convert_dateb_udf(col('transaction_date')))))\\\n",
    "\n",
    "    cmovpf = cmovpf.withColumn(\"d_clo\",when(col('clstat')==2, col('d_tran')).otherwise(errdate))\n",
    "    cmovpf = cmovpf.withColumn(\"yrm\", col('batcactyr')*100+col('batcactmn'))\n",
    "    cmovpf = cmovpf.withColumn(\"paymntid\",when(col('reqnno').isNotNull() & (trim(col('reqnno'))!=''),col('reqnno')).\\\n",
    "                               when(col('receipt').isNotNull() & (col('receipt')!=''),col('receipt')).otherwise(lit(\"NA\")))\n",
    "\n",
    "    cmovpf = cmovpf.withColumnRenamed(\"paymnt\",\"gpaytot\").\\\n",
    "             withColumnRenamed(\"chgbal\",\"gmovtot\").\\\n",
    "             withColumnRenamed(\"paymnt_ri\",\"rpaytot\").\\\n",
    "             withColumnRenamed(\"chgbal_ri\",\"rmovtot\")\n",
    "\n",
    "    cmovpf = cmovpf.drop('transaction_date','batcactyr','batcactmn','clmpfx','clmcoy','validflag','reqnno','receipt')\n",
    "    cmovpf.cache()\n",
    "\n",
    "    # ************************* FIRST GET BASE ************************* \n",
    "    base = cmovpf.drop('gpaytot','gmovtot','rpaytot','rmovtot')\n",
    "    base = base.orderBy('claim','tranno').dropDuplicates(['claim','tranno'])\n",
    "    base.cache()\n",
    "\n",
    "    # ********************** THEN AGGREGATE CMOVPF ********************* */ \n",
    "    cmovpf_sum = cmovpf.groupBy('claim','tranno').sum('gpaytot','gmovtot','rpaytot','rmovtot')\\\n",
    "    .withColumnRenamed('sum(gpaytot)','gpaytot')\\\n",
    "    .withColumnRenamed('sum(gmovtot)','gmovtot')\\\n",
    "    .withColumnRenamed('sum(rpaytot)','rpaytot')\\\n",
    "    .withColumnRenamed('sum(rmovtot)','rmovtot')\n",
    "\n",
    "    #*----------------------------------------------------------*/\n",
    "    #*                          PART II                         */\n",
    "    #*----------------------------------------------------------*/\n",
    "\n",
    "    # Get detail of Gross Claim info in CTRNPF\n",
    "\n",
    "    ctrnpf = ctrnpf[['clmpfx','clmcoy','claim','tranno','prcl','rscd','paymnt','chgbal']]\\\n",
    "             .filter((col('clmpfx')=='CL') & (col('clmcoy')==1))\n",
    "\n",
    "    ctrnpf = ctrnpf.withColumn(\"prcl_rscd\", concat(col('prcl'), col('rscd')))\n",
    "    ctrnpf = ctrnpf.withColumnRenamed(\"paymnt\",\"gpay\").withColumnRenamed(\"chgbal\",\"gmov\")\n",
    "    ctrnpf.cache()\n",
    "\n",
    "    classes = ctrnpf[['claim','prcl_rscd']].orderBy(['claim','prcl_rscd']).dropDuplicates(['claim','prcl_rscd'])\n",
    "    trannos = cmovpf[['claim','tranno']].orderBy(['claim','tranno']).dropDuplicates(['claim','tranno'])\n",
    "\n",
    "    template = trannos.join(classes, trannos['claim'] == classes['claim'], 'left')\n",
    "    template = template.select([trannos[c] for c in trannos.columns]+[classes['prcl_rscd']])\n",
    "    template = template.orderBy('claim', 'tranno', 'prcl_rscd')\n",
    "\n",
    "    # Remove records which does not exist in CMOVPF \n",
    "    # since we need to recon with CMOVPF\n",
    "    ctrnpf = base[['claim','tranno']].join(ctrnpf, ['claim','tranno'], 'left').fillna(0, subset=['gpay','gmov'])\n",
    "\n",
    "    # Aggregate on granular level\n",
    "    ctrnpf = ctrnpf.groupBy('claim','tranno','prcl_rscd').sum('gpay','gmov')\\\n",
    "    .withColumnRenamed('sum(gpay)','gpay')\\\n",
    "    .withColumnRenamed('sum(gmov)','gmov')\n",
    "\n",
    "    ctrnpf = template.join(ctrnpf,on=['claim','tranno','prcl_rscd'],how='left').fillna(0, subset=['gpay','gmov'])\n",
    "\n",
    "    # Aggregate gross claim info in CTRNPF for recon\n",
    "    ctrnpf_sum = ctrnpf.groupBy('claim','tranno').agg(sum('gpay'),sum('gmov'),count(lit(1)))\\\n",
    "    .withColumnRenamed('sum(gpay)','gpay')\\\n",
    "    .withColumnRenamed('sum(gmov)','gmov')\\\n",
    "    .withColumnRenamed('count(1)','nbkeys')\n",
    "    ctrnpf_sum.cache()\n",
    "\n",
    "    #*-----------------------------------------------------------*/\n",
    "    #*                          PART III                         */\n",
    "    #*-----------------------------------------------------------*/\n",
    "\n",
    "    recon_cl_gr_psea_recon = cmovpf_sum.drop('rpaytot','rmovtot').join(ctrnpf_sum.drop('nbkeys'),on=['claim','tranno'],how='left')\\\n",
    "    .fillna(0, subset=['gpay','gmov'])\\\n",
    "    .withColumn('err_pay',when(abs(col('gpay')-col('gpaytot'))>0.01,lit(1)).otherwise(lit(0)))\\\n",
    "    .withColumn('err_mov',when(abs(col('gmov')-col('gmovtot'))>0.01,lit(1)).otherwise(lit(0)))\\\n",
    "    .filter((col('err_pay')==1) | (col('err_mov')==1))\n",
    "\n",
    "    recon_cl_gr_psea_recon.write.parquet('{}recon_cl_gr_psea_recon.parquet'.format(output_folder))\n",
    "\n",
    "    #*-----------------------------------------------------------*/\n",
    "    #*                          PART IV                          */\n",
    "    #*-----------------------------------------------------------*/\n",
    "    # Aggregate reinsurance claim info in LTRNPF for recon\n",
    "    ltrnpf = ltrnpf[['clmpfx','clmcoy','claim','tranno','lactyp','paymnt_ri','chgbal_ri']]\\\n",
    "    .filter((col('clmpfx')=='CL') & (col('clmcoy')==1))\\\n",
    "    .withColumn('cpay',when(col('lactyp')=='I',col('paymnt_ri')).otherwise(lit(0)))\\\n",
    "    .withColumn('cmov',when(col('lactyp')=='I',col('chgbal_ri')).otherwise(lit(0)))\\\n",
    "    .withColumn('rpay',when(col('lactyp')=='I',lit(0)).otherwise(col('paymnt_ri')))\\\n",
    "    .withColumn('rmov',when(col('lactyp')=='I',lit(0)).otherwise(col('chgbal_ri')))\\\n",
    "    .drop('clmpfx','clmcoy','lactyp','paymnt_ri','chgbal_ri')\n",
    "\n",
    "    # Remove records which don't exist in CMOVPF since we need to recon with CMOVPF\n",
    "\n",
    "    ltrnpf = base[['claim','tranno']].join(ltrnpf, on=['claim','tranno'],how='left').fillna(0, subset=['cpay','cmov','rpay','rmov'])\n",
    "    ltrnpf.cache()\n",
    "    # Aggregate on granular level - here it is claim tranno since this is the most granular level\n",
    "    # (and we need it more granular we will merge it later)\n",
    "\n",
    "    ltrnpf_sum = ltrnpf.groupBy('claim','tranno').sum('cpay','cmov','rpay','rmov')\\\n",
    "    .withColumnRenamed('sum(cpay)','cpay').withColumnRenamed('sum(cmov)','cmov')\\\n",
    "    .withColumnRenamed('sum(rpay)','rpay').withColumnRenamed('sum(rmov)','rmov')\n",
    "\n",
    "    #*----------------------------------------------------------*/\n",
    "    #*                          PART V                          */\n",
    "    #*----------------------------------------------------------*/\n",
    "    # Reconcile the data\n",
    "    # Recon - can only recon reinsurance total and not split by RI and CO, since in the \n",
    "    # CMOVPF table we do not have the information on the reinsurance\n",
    "    # What this means is that we don't have an rpaytot and a cpaytot in CMOVPF_SUM,\n",
    "    # we are unable to split in CMOVPF between CO in RI.\n",
    "\n",
    "    recon_cl_ri_psea_recon = cmovpf_sum.drop('gmovtot','gpaytot').join(ltrnpf_sum,on=['claim','tranno'],how='left')\\\n",
    "    .fillna(0, subset=['cpay','cmov','rpay','rmov'])\\\n",
    "    .withColumn('err_pay',when(abs(col('cpay')+col('rpay')-col('rpaytot'))>0.01,lit(1)).otherwise(lit(0)))\\\n",
    "    .withColumn('err_mov',when(abs(col('cmov')+col('rmov')-col('rmovtot'))>0.01,lit(1)).otherwise(lit(0)))\\\n",
    "    .filter((col('err_pay')==1) | (col('err_mov')==1))\n",
    "\n",
    "    recon_cl_ri_psea_recon.write.parquet('{}recon_cl_ri_psea_recon.parquet'.format(output_folder))\n",
    "\n",
    "    #*-----------------------------------------------------------*/\n",
    "    #*                          PART VI                          */\n",
    "    #*-----------------------------------------------------------*/\n",
    "    # Aggregate LTRNPF\n",
    "    # Note on retain - it\n",
    "    ltrnpf_sum2 = ltrnpf_sum\\\n",
    "    .withColumn('cpay_cum_tranno',sum('cpay').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumn('cmov_cum_tranno',sum('cmov').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumn('rpay_cum_tranno',sum('rpay').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumn('rmov_cum_tranno',sum('rmov').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumnRenamed('cpay','cpay_aggr')\\\n",
    "    .withColumnRenamed('cmov','cmov_aggr')\\\n",
    "    .withColumnRenamed('rpay','rpay_aggr')\\\n",
    "    .withColumnRenamed('rmov','rmov_aggr')\n",
    "\n",
    "    # Aggregate CTRNPF\n",
    "    ctrnpf_sum2 = ctrnpf_sum\\\n",
    "    .withColumn('gpay_cum_tranno',sum('gpay').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumn('gmov_cum_tranno',sum('gmov').over(Window.partitionBy('claim').orderBy('tranno')))\\\n",
    "    .withColumnRenamed('gpay','gpay_aggr')\\\n",
    "    .withColumnRenamed('gmov','gmov_aggr')\n",
    "\n",
    "    # Merge\n",
    "    # Use this instead of making a condition on each Numeric field that if it is . you make it 0\n",
    "    quanti_psea = ctrnpf.join(ltrnpf_sum2, on=['claim','tranno'],how ='outer')\\\n",
    "                        .join(ctrnpf_sum2, on =['claim','tranno'],how ='left').fillna(0)\n",
    "\n",
    "\n",
    "    # Proportion the reinsurance to granularity\n",
    "    # Cumulate on gpay and gmov since this is all you know up to now\n",
    "    quanti_psea2 = quanti_psea\\\n",
    "    .withColumn('gpay_cum_pr_rsv',sum('gpay').over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno')))\\\n",
    "    .withColumn('gmov_cum_pr_rsv',sum('gmov').over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno')))\n",
    "\n",
    "    quanti_psea2 = quanti_psea2\\\n",
    "    .withColumn('prop_pay', when(col('gpay_cum_tranno')!=0, col('gpay_cum_pr_rsv')/col('gpay_cum_tranno')).\\\n",
    "                when(col('nbkeys')!=0, 1/col('nbkeys')).otherwise(lit(1)))\\\n",
    "    .withColumn('prop_mov', when(col('gmov_cum_tranno')!=0, col('gmov_cum_pr_rsv')/col('gmov_cum_tranno')).\\\n",
    "               when(col('nbkeys')!=0, 1/col('nbkeys')).otherwise(lit(1)))\\\n",
    "    .withColumn('cpay_cum_pr_rsv',col('prop_pay') * col('cpay_cum_tranno'))\\\n",
    "    .withColumn('rpay_cum_pr_rsv',col('prop_pay') * col('rpay_cum_tranno'))\\\n",
    "    .withColumn('cmov_cum_pr_rsv',col('prop_mov') * col('cmov_cum_tranno'))\\\n",
    "    .withColumn('rmov_cum_pr_rsv',col('prop_mov') * col('rmov_cum_tranno'))\n",
    "\n",
    "    # Get incremental for CO and RI\n",
    "    quanti_psea2 = quanti_psea2\\\n",
    "    .withColumn('firstclaim',row_number().over(Window.partitionBy('claim').orderBy('prcl_rscd','tranno')))\\\n",
    "    .withColumn('firstprcl',row_number().over(Window.partitionBy('claim','prcl_rscd').orderBy('tranno')))\\\n",
    "    .withColumn('lastclaim',row_number().over(Window.partitionBy('claim').orderBy(desc('prcl_rscd'),desc('tranno'))))\\\n",
    "    .withColumn('lastprcl',row_number().over(Window.partitionBy('claim','prcl_rscd').orderBy(desc('tranno'))))\\\n",
    "    .withColumn('cpay',when(col('firstprcl')==1,col('cpay_cum_pr_rsv'))\\\n",
    "               .otherwise(col('cpay_cum_pr_rsv')-lag(col('cpay_cum_pr_rsv')).over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno'))))\\\n",
    "    .withColumn('rpay',when(col('firstprcl')==1,col('rpay_cum_pr_rsv'))\\\n",
    "               .otherwise(col('rpay_cum_pr_rsv')-lag(col('rpay_cum_pr_rsv')).over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno'))))\\\n",
    "    .withColumn('cmov',when(col('firstprcl')==1,col('cmov_cum_pr_rsv'))\\\n",
    "               .otherwise(col('cmov_cum_pr_rsv')-lag(col('cmov_cum_pr_rsv')).over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno'))))\\\n",
    "    .withColumn('rmov',when(col('firstprcl')==1,col('rmov_cum_pr_rsv'))\\\n",
    "               .otherwise(col('rmov_cum_pr_rsv')-lag(col('rmov_cum_pr_rsv')).over(Window.partitionBy('claim','prcl_rscd').orderBy('prcl_rscd','tranno'))))\\\n",
    "    .withColumn('rmov_cmov_error_flag',when((col('lastclaim')==1) |\n",
    "                                            (col('lastprcl')==1) |\n",
    "                                            ((col('gmov_cum_pr_rsv')==0) & (col('rmov_cum_pr_rsv')!=0)), lit(1)))\\\n",
    "    .select('claim','tranno','prcl_rscd','gpay','gmov','cpay','cmov','rpay','rmov')\n",
    "\n",
    "    # \t/*----------------------------------------------------------*/\n",
    "    # \t/* \t\t\t\t\t\t  PART VII\t\t\t\t\t\t\t*/\n",
    "    # \t/*----------------------------------------------------------*/\n",
    "\n",
    "    # Finalize by adding qualitative information\n",
    "    cl_quanti_psea = base.join(quanti_psea2,on=['claim','tranno'], how='left')\n",
    "\n",
    "    #/* Manual Adjustments from Mapping File :\n",
    "    #\t\tCases where Balo of CLAMPF doesn't reconcile\n",
    "    #\t\twith the sum of CHGBAL in CMOVPF\t\t\t*/\n",
    "    #MISSING\n",
    "\n",
    "    cl_quanti_psea.write.parquet('{}transv_cl_quanti_psea.parquet'.format(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def claims_quali_psea(transv_cl_quanti_psea_path, clampf_path, clxdpf_path, cal_ymd, adm_mapping_path, output_folder = 'data/sas_403/'):\n",
    "    \n",
    "    transv_cl_quanti_psea = spark.read.parquet(transv_cl_quanti_psea_path)\n",
    "    clampf = spark.read.parquet(clampf_path)\n",
    "    clxdpf = spark.read.parquet(clxdpf_path)\n",
    "    \n",
    "    #******************************************************************\n",
    "    #**************************** GET BASE **************************** \n",
    "    #******************************************************************\n",
    "    \n",
    "    basequali = transv_cl_quanti_psea[['claim','d_tran','d_clo']]\n",
    "    basequali.cache()\n",
    "\n",
    "    # Keep firsts registration date only\n",
    "    basequalireg = basequali.drop('d_clo').withColumnRenamed('d_tran','d_reg').orderBy('claim').dropDuplicates(['claim'])\n",
    "\n",
    "    # Keep closing date only\n",
    "    basequaliclo = basequali.withColumn('rownum',row_number().over(Window.partitionBy('claim').orderBy(desc('D_tran'))))\n",
    "    basequaliclo = basequaliclo.filter(col('rownum')==1).drop('d_tran','rownum')\n",
    "\n",
    "    basequali1 = basequalireg.join(basequaliclo,on='claim',how='inner')\n",
    "\n",
    "    #******************************************************************\n",
    "    #******************* CLEAN QUALITATIVE TABLES *********************\n",
    "    #******************************************************************\n",
    "    \n",
    "    clampf = clampf.select('claim','chdrstcda','chdrstcdc','agntnum','clntnum','chdrnum',\n",
    "                           'datrep','datocc','rskno','cnttype','rsktyp','clmdsc',\n",
    "                           'cedref','zrepclmno','assess','assessdt','solict','solictdt',\n",
    "                           'clrvwdat','user_profile','clstat','clcurr','subrec','id',\n",
    "                           'mevent','validflag','coppn','servbr','tparty')\\\n",
    "    .filter(col('validflag')==1).orderBy('claim').dropDuplicates(subset=['claim'])\n",
    "\n",
    "    # CLXDPF - Extra claim info\n",
    "    # Normally each row should be unique by claim\n",
    "    \n",
    "    clxdpf = clxdpf.select('claim','ccdate','dteeff','crdate','acstyp','desc01','desc02','validflag')\\\n",
    "    .filter(col('validflag')==1).orderBy('claim').dropDuplicates(subset=['claim'])\n",
    "\n",
    "    # Merge with base and clean variables\n",
    "    cl_quali_psea = basequali1.join(clampf,on='claim',how='left').join(clxdpf, on='claim',how='left')\n",
    "    \n",
    "    # Format dates\n",
    "    # Reported, occurred appointment and review dates\n",
    "    \n",
    "    cl_quali_psea = cl_quali_psea\\\n",
    "    .withColumn('d_com', to_date(_format_date(col('ccdate'))))\\\n",
    "    .withColumn('d_exp', to_date(_format_date(col('crdate'))))\\\n",
    "    .withColumn('d_eff', to_date(_format_date(col('dteeff'))))\\\n",
    "    .withColumn('d_rep', to_date(_format_date(col('datrep'))))\\\n",
    "    .withColumn('d_occ', to_date(_format_date(col('datocc'))))\\\n",
    "    .withColumn('assessdt', when(col('assessdt')>cal_ymd,lit(0)).otherwise(col('assessdt')))\\\n",
    "    .withColumn('d_app_a', to_date(_format_date(col('assessdt'))))\\\n",
    "    .withColumn('d_app_s', to_date(_format_date(col('solictdt'))))\\\n",
    "    .withColumn('d_review', to_date(_format_date(col('clrvwdat'))))\\\n",
    "    .withColumnRenamed('chdrstcda','fundcode')\\\n",
    "    .withColumnRenamed('agntnum','agentid')\\\n",
    "    .withColumnRenamed('clntnum','claimantid')\\\n",
    "    .withColumn('clmdesc1',lower(trim(col('clmdsc'))))\\\n",
    "    .withColumn('clmdesc2',lower(trim(col('desc01'))))\\\n",
    "    .withColumn('clmdesc3',lower(trim(col('desc02'))))\\\n",
    "    .withColumnRenamed('user_profile','examiner')\\\n",
    "    .withColumnRenamed('id','officerid')\\\n",
    "    .withColumn('assessor',when(col('assess').isNotNull(), col('assess')).otherwise(lit('NA')))\\\n",
    "    .withColumn('solicitor',when(col('solict').isNotNull(), col('solict')).otherwise(lit('NA')))\\\n",
    "    .drop('datrep','datocc','clmdsc','validflag',\n",
    "          'clrvwdat','assess','solict','soilctdt','assessdt',\n",
    "          'ccdate','dteeff','crdate','desc01','desc02')\n",
    "    \n",
    "    # Read in the mappings file\n",
    "    \n",
    "    # Nat Cat\n",
    "    natcat_map = pd.read_excel(adm_mapping_path, sheetname = '111')\n",
    "    natcat_map['mevent'] = natcat_map['mevent'].astype(str)\n",
    "    \n",
    "    transv_cl_quali_psea = cl_quali_psea.join(broadcast(spark.createDataFrame(natcat_map)),on=['chdrstcdc','mevent'],how='left')\\\n",
    "    .drop('clstat').fillna(0,'natcat')\n",
    "    \n",
    "    transv_cl_quali_psea.write.parquet('{}transv_cl_quali_psea.parquet'.format(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmovpf_path = '/group/axa_malaysia/data/adm_cmovpf'\n",
    "ctrnpf_path = '/group/axa_malaysia/data/adm_ctrnpf'\n",
    "ltrnpf_path = '/group/axa_malaysia/data/adm_ltrnpf'\n",
    "clampf_path = '/group/axa_malaysia/data/adm_clampf'\n",
    "clxdpf_path = '/group/axa_malaysia/data/adm_clxdpf'\n",
    "transv_cl_quanti_psea_path = 'data/sas_403/transv_cl_quanti_psea.parquet'\n",
    "adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "cal_yr = datetime.now().year\n",
    "cal_mth = datetime.now().month\n",
    "cal_day = datetime.now().day\n",
    "cal_yrm = cal_yr*100 + cal_mth\n",
    "cal_ymd = cal_yrm*100 + cal_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "claims_quanti_psea(cmovpf_path, ctrnpf_path, ltrnpf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "claims_quali_psea(transv_cl_quanti_psea_path, clampf_path, clxdpf_path, cal_ymd, adm_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4939745"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_quanti_psea.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(gpay)=4038300006.249997, sum(gmov)=721206971.5299996, sum(cpay)=111049582.85000004, sum(cmov)=30006078.270000014, sum(rpay)=642499920.3862486, sum(rmov)=144475273.68999955)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_quanti_psea.groupby().sum('gpay','gmov','cpay','cmov','rpay','rmov').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = spark.createDataFrame([[300,1,1],[250,2,2],[100,3,3],[75,4,4]],['rmov_cum_pr_rsv','firstclaim','firstprcl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+\n",
      "|rmov_cum_pr_rsv|firstclaim|firstprcl|\n",
      "+---------------+----------+---------+\n",
      "|            300|         1|        1|\n",
      "|            250|         2|        2|\n",
      "|            100|         3|        3|\n",
      "|             75|         4|        4|\n",
      "+---------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing = testing.withColumn('tmp_rmov_cum_pr_rsv', when((col('firstclaim')==1)|(col('firstprcl')==1), col('rmov_cum_pr_rsv'))\\\n",
    "           .otherwise(-col('rmov_cum_pr_rsv')))\\\n",
    ".withColumn('rmov', sum('tmp_rmov_cum_pr_rsv').over(Window.partitionBy().orderBy('firstclaim')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-------------------+----+\n",
      "|rmov_cum_pr_rsv|firstclaim|firstprcl|tmp_rmov_cum_pr_rsv|rmov|\n",
      "+---------------+----------+---------+-------------------+----+\n",
      "|            300|         1|        1|                300| 300|\n",
      "|            250|         2|        2|               -250|  50|\n",
      "|            100|         3|        3|               -100| -50|\n",
      "|             75|         4|        4|                -75|-125|\n",
      "+---------------+----------+---------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = testing.withColumn('rmovtest',col('rmov_cum_pr_rsv')-lag(col('rmov_cum_pr_rsv')).over(Window.partitionBy().orderBy('firstclaim')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-------------------+----+--------+\n",
      "|rmov_cum_pr_rsv|firstclaim|firstprcl|tmp_rmov_cum_pr_rsv|rmov|rmovtest|\n",
      "+---------------+----------+---------+-------------------+----+--------+\n",
      "|            300|         1|        1|                300| 300|     300|\n",
      "|            250|         2|        2|               -250|  50|     -50|\n",
      "|            100|         3|        3|               -100| -50|    -150|\n",
      "|             75|         4|        4|                -75|-125|     -25|\n",
      "+---------------+----------+---------+-------------------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.withColumn('rmovtest',when(col('firstclaim')==1,col('rmov_cum_pr_rsv')).otherwise(col('rmovtest'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adm_mapping_path = 'ADM Mapping.xlsm'\n",
    "ztrnpf_path = '/river/axa_my/axa_aaro_psea/data/psea_ztrnpf/merge/yyyy=2027/mm=10/dd=31'\n",
    "monthend = 1\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "def format_date(strdate):\n",
    "    try: \n",
    "        return datetime.strptime(str(strdate),'%Y%m%d').strftime('%Y-%m-%d')\n",
    "    except: \n",
    "        return '2999-12-31'\n",
    "_format_date = udf(format_date,StringType())\n",
    "\n",
    "\"\"\"\n",
    "    /* 1) sacscode filter */\n",
    "    /* Consider Gross Prem (FG) and Co-insurance Prem      */\n",
    "    /* we will consider RP (Re-insurance premium) in  \t   */\n",
    "    /* the next section, since it only needs to run   \t   */\n",
    "    /* once a month - it is a massive table\t\t\t       */\n",
    "    /* 2) batctrcde filter */\n",
    "    /* Only consider real financial transactions      \t   */\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    /* Map Transaction Types */\n",
    "    /* Note - the mapping is limited to the filter, so the mapping is only needed for the\n",
    "       transaction types applied in the filter */\n",
    "    Transaction Types are read from the excel mapping files\n",
    "\"\"\"\n",
    "transtype_map = pd.read_excel(adm_mapping_path, sheetname='300').set_index('batctrcde').to_dict()['trantype']\n",
    "transtype_map_bc = sc.broadcast(transtype_map)\n",
    "\n",
    "ztrnpf = spark.read.parquet(ztrnpf_path)[['batcactyr',\n",
    " 'batcactmn',\n",
    " 'rldgacct',\n",
    " 'tranno',\n",
    " 'ccdate',\n",
    " 'effdate',\n",
    " 'accnum',\n",
    " 'expiry_date',\n",
    " 'batctrcde',\n",
    " 'sacscode',\n",
    " 'trandate',\n",
    " 'chdrstcdc',\n",
    " 'tranamt01',\n",
    " 'tranamt02',\n",
    " 'tranamt03',\n",
    " 'tranamt04',\n",
    " 'tranamt05',\n",
    " 'tranamt14',\n",
    " 'batcbrn']].filter( col(\"batctrcde\").isin(['TA39','T409','T44B','T922','T405','T903','T413','T927','T928',\n",
    "                                            'BA25','T454','T467','T913','T914','T926','T930','T934','T931']) )#.limit(100000)\n",
    "#'B470','T46B','T475','T840','B920','BR9A','T8A0','T933'\n",
    "ztrnpf_fgco = ztrnpf\n",
    "\"\"\"\n",
    "ztrnpf_fgco = ztrnpf.filter(col(\"sacscode\").isin(\"FG\",\"CO\"))\n",
    "ztrnpf_rp = ztrnpf.filter(col(\"sacscode\")=='RP')\n",
    "\"\"\"\n",
    "def transformations(df):\n",
    "    df = df.withColumn('yrm', col('batcactyr')*100+col('batcactmn'))\n",
    "\n",
    "    #dates formatting\n",
    "    df = df.withColumn('d_tran', to_date(_format_date(col('trandate'))))\\\n",
    "    .withColumn('d_eff', to_date(_format_date(col('effdate'))))\\\n",
    "    .withColumn('d_com', to_date(_format_date(col('ccdate'))))\\\n",
    "    .withColumn('d_exp', to_date(_format_date(col('expiry_date'))))\n",
    "\n",
    "    df = df.drop('batcactyr','batcactmn','effdate','ccdate','expiry_date','trandate','tranamt01','tranamt02','tranamt03','tranamt04',\n",
    "                 'tranamt05','tranamt14')\n",
    "\n",
    "    #map transaction types\n",
    "    df = df.withColumn('trantype', udf(lambda x: transtype_map_bc.value.get(x,'NA'))(col('batctrcde')))\n",
    "    return df\n",
    "\n",
    "df1 = ztrnpf.withColumnRenamed('rldgacct', 'chdrnum')\\\n",
    "            .withColumnRenamed('accnum', 'agentid')\n",
    "\n",
    "df2 = df1.withColumn('fg_gr_premium_total', when(col('sacscode').isin(['FG','GR']), col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('fg_gr_commission_total', when(col('sacscode').isin(['FG','GR']), col('tranamt04') + col('tranamt05')).otherwise(0) )\\\n",
    ".withColumn('co_premium_total', when(col('sacscode')=='CO', col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('co_commission_total', when(col('sacscode')=='CO', col('tranamt04') + col('tranamt05')).otherwise(0) )\\\n",
    ".withColumn('rp_premium_total', when(col('sacscode')=='RP', col('tranamt01') - col('tranamt03') + col('tranamt14')).otherwise(0) )\\\n",
    ".withColumn('rp_commission_total', when(col('sacscode')=='RP', col('tranamt04') + col('tranamt05')).otherwise(0) )\n",
    "\n",
    "df3 = transformations(df2)\n",
    "\n",
    "df4 = df3.groupBy('chdrnum','tranno', 'batcbrn', 'yrm').sum('fg_gr_premium_total',\n",
    "                                          'fg_gr_commission_total',\n",
    "                                          'co_premium_total',\n",
    "                                          'co_commission_total',\n",
    "                                          'rp_premium_total',\n",
    "                                          'rp_commission_total')\\\n",
    ".withColumnRenamed('sum(fg_gr_premium_total)','fg_gr_premium_total')\\\n",
    ".withColumnRenamed('sum(fg_gr_commission_total)','fg_gr_commission_total')\\\n",
    ".withColumnRenamed('sum(co_premium_total)','co_premium_total')\\\n",
    ".withColumnRenamed('sum(co_commission_total)','co_commission_total')\\\n",
    ".withColumnRenamed('sum(rp_premium_total)','rp_premium_total')\\\n",
    ".withColumnRenamed('sum(rp_commission_total)','rp_commission_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+------+--------+--------+------+-----------+---------+--------+--------+---------+---------+---------+---------+---------+---------+---------+-------+\n",
      "|batcactyr|batcactmn|rldgacct|tranno|  ccdate| effdate|accnum|expiry_date|batctrcde|sacscode|trandate|chdrstcdc|tranamt01|tranamt02|tranamt03|tranamt04|tranamt05|tranamt14|batcbrn|\n",
      "+---------+---------+--------+------+--------+--------+------+-----------+---------+--------+--------+---------+---------+---------+---------+---------+---------+---------+-------+\n",
      "|     2008|        4|01748131|     2|20080328|20080328| 22929|   20090327|     T928|      GR|20080402|      AHX|  1727.00|    10.00|     0.00|   259.05|     0.00|     0.00|     89|\n",
      "|     2017|        5|01748131|    11|20170328|20170328| 22929|   20180327|     T928|      GR|20170511|      AHX|  4289.00|    10.00|     0.00|   643.35|     0.00|     0.00|     89|\n",
      "|     2014|        4|01748131|     8|20140328|20140328| 22929|   20150327|     T928|      GR|20140403|      AHX|  2643.00|    10.00|     0.00|   396.45|     0.00|     0.00|     89|\n",
      "|     2013|        5|01748131|     7|20130328|20130328| 22929|   20140327|     T928|      GR|20130426|      AHX|  2510.00|    10.00|     0.00|   376.50|     0.00|     0.00|     89|\n",
      "|     2012|        4|01748131|     6|20120328|20120328| 22929|   20130327|     T928|      GR|20120421|      AHX|  2103.00|    10.00|     0.00|   315.45|     0.00|     0.00|     89|\n",
      "|     2011|        4|01748131|     5|20110328|20110328| 22929|   20120327|     T928|      GR|20110411|      AHX|  2008.00|    10.00|     0.00|   301.20|     0.00|     0.00|     89|\n",
      "|     2009|        4|01748131|     3|20090328|20090328| 22929|   20100327|     T928|      GR|20090402|      AHX|  1823.00|    10.00|     0.00|   273.45|     0.00|     0.00|     89|\n",
      "|     2016|        4|01748131|    10|20160328|20160328| 22929|   20170327|     T928|      GR|20160419|      AHX|  4026.00|    10.00|     0.00|   603.90|     0.00|     0.00|     89|\n",
      "|     2007|        3|01748131|     1|20070328|20070328| 22929|   20080327|     T903|      GR|20070330|      AHX|  1631.00|    10.00|     0.00|   244.65|     0.00|     0.00|     89|\n",
      "|     2010|        3|01748131|     4|20100328|20100328| 22929|   20110327|     T928|      GR|20100316|      AHX|  1917.00|    10.00|     0.00|   287.55|     0.00|     0.00|     89|\n",
      "|     2015|        4|01748131|     9|20150328|20150328| 22929|   20160327|     T928|      GR|20150407|      AHX|  3779.00|    10.00|     0.00|   566.85|     0.00|     0.00|     89|\n",
      "+---------+---------+--------+------+--------+--------+------+-----------+---------+--------+--------+---------+---------+---------+---------+---------+---------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ztrnpf.filter(col('rldgacct')=='01748131').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3[['chdrnum','tranno', 'batcbrn', 'yrm', 'sacscode', 'batctrcde',\n",
    "     'fg_gr_premium_total',\n",
    "     'fg_gr_commission_total',\n",
    "     'co_premium_total',\n",
    "     'co_commission_total',\n",
    "     'rp_premium_total',\n",
    "     'rp_commission_total'\n",
    "    ]].withColumn('tranno',col('tranno').cast('string'))\\\n",
    ".withColumn('yrm',col('yrm').cast('string'))\\\n",
    ".withColumn('fg_gr_premium_total',col('fg_gr_premium_total').cast('float'))\\\n",
    ".withColumn('fg_gr_commission_total',col('fg_gr_commission_total').cast('float'))\\\n",
    ".withColumn('co_premium_total',col('co_premium_total').cast('float'))\\\n",
    ".withColumn('co_commission_total',col('co_commission_total').cast('float'))\\\n",
    ".withColumn('rp_premium_total',col('rp_premium_total').cast('float'))\\\n",
    ".withColumn('rp_commission_total',col('rp_commission_total').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+------+--------+---------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "| chdrnum|tranno|batcbrn|   yrm|sacscode|batctrcde|fg_premium_total|fg_commission_total|co_premium_total|co_commission_total|rp_premium_total|rp_commission_total|\n",
      "+--------+------+-------+------+--------+---------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "|01748131|     2|     89|200804|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|    11|     89|201705|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     8|     89|201404|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     7|     89|201305|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     6|     89|201204|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     5|     89|201104|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     3|     89|200904|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|    10|     89|201604|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     1|     89|200703|      GR|     T903|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     4|     89|201003|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "|01748131|     9|     89|201504|      GR|     T928|             0.0|                0.0|             0.0|                0.0|             0.0|                0.0|\n",
      "+--------+------+-------+------+--------+---------+----------------+-------------------+----------------+-------------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.filter(col('chdrnum')=='01748131').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.write.saveAsTable('axa_malaysia.pr_gr_psea24', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = df4.withColumn('tranno',col('tranno').cast('string')).withColumn('yrm',col('yrm').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.write.saveAsTable('axa_malaysia.pr_gr_psea18', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 2.0.0 - YARN [anaconda3-4.1.1]",
   "language": "",
   "name": "pyspark2_yarn_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
